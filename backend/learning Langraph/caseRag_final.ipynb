{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d131b9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from operator import add as add_messages\n",
    "\n",
    "\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import chromadb\n",
    "import requests\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8def872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mawiy\\OneDrive\\Desktop\\Legal-Agent\\myLegal\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "pdf_path ='pdf/Fundamentals of Building Autonomous LLM.pdf'\n",
    "pages = PyPDFLoader(pdf_path).load()\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15a974f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter= RecursiveCharacterTextSplitter(chunk_size =1000, chunk_overlap=200,separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \" \",\n",
    "        \"\"\n",
    "        ])\n",
    "\n",
    "pages_split=text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8ec2bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = r\"C:\\Users\\mawiy\\OneDrive\\Desktop\\Legal-Agent\\learning Langraph\\pdf\"\n",
    "\n",
    "collection_name = \"cases\"\n",
    "\n",
    "# If our collection does not exist in the directory, we create using the os command\n",
    "if not os.path.exists(persist_directory):\n",
    "    os.makedirs(persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4df31461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 0, 'page_label': '1'}, page_content='Fundamentals of Building Autonomous LLM\\nAgents ⋆\\nVictor de Lamo Castrillo1 , Habtom Kahsay Gidey2 , Alexander Lenz2 , and\\nAlois Knoll2\\n1 Universitat Politècnica de Catalunya, Barcelona, Spain\\nvictor.de.lamo@estudiantat.upc.edu\\n2 Technische Universität München, München, Germany\\n{habtom.gidey, alex.lenz, knoll}@tum.de\\nAbstract. This paper reviews the architecture andimplementation meth-\\nods of agents powered by large language models (LLMs). Motivated by\\nthe limitations of traditional LLMs in real-world tasks, the research aims\\nto explore patterns to develop “agentic” LLMs that can automate complex\\ntasks and bridge the performance gap with human capabilities. Key com-\\nponents include a perception system that converts environmental percepts\\ninto meaningful representations; a reasoning system that formulates plans,\\nadapts to feedback, and evaluates actions through different techniques like\\nChain-of-Thought and Tree-of-Thought; a memory system that retains'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 0, 'page_label': '1'}, page_content='adapts to feedback, and evaluates actions through different techniques like\\nChain-of-Thought and Tree-of-Thought; a memory system that retains\\nknowledge through both short-term and long-term mechanisms; and an\\nexecution system that translates internal decisions into concrete actions.\\nThis paper shows how integrating these systems leads to more capable\\nand generalized software bots that mimic human cognitive processes for\\nautonomous and intelligent behavior.\\nKeywords:Autonomous LLM Agents·Perception·Reasoning and\\nPlanning·Memory Systems·Action Systems·Multi-agent Systems\\n1 Introduction\\n1.1 Motivation\\nArtificial intelligence (AI) is a powerful technology that is transforming cognitive\\nautomation and fundamentally reshaping the way tasks are performed [13,14,37].\\nToday, one can develop remarkable systems without the need to write complex\\nalgorithms or master low-level code. We are closer than ever to realizing the'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 0, 'page_label': '1'}, page_content='Today, one can develop remarkable systems without the need to write complex\\nalgorithms or master low-level code. We are closer than ever to realizing the\\nidea that “if you can think it, you can build it.” Instead of relying solely on\\nprogramming skills, what increasingly matters is understanding how a human\\nwould reason through a problem, since LLM agents can learn and mimic human\\nproblem solving by externalizing intermediate reasoning and refining it through\\nself-feedback [26,38,49,58,60,65,66].\\n⋆ This paper is based on a seminar technical report from the courseTrends in Au-\\ntonomous Agents: Advances in Architecture and Practiceoffered at TUM.\\narXiv:2510.09244v1  [cs.AI]  10 Oct 2025'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 1, 'page_label': '2'}, page_content='2 de Lamo et al.\\nLLM agents represent a new paradigm that breaks traditional barriers. They\\nenable the execution of tasks that were previously costly, time-consuming, or\\neven infeasible. More than tools, agents act as collaborators, assisting humans\\nin dynamic environments and automating decision-making in critical systems.\\nHowever, this transformation is still in its early stages. Engaging with LLM agents\\nis comparable to engaging with a new species, one that we are only beginning to\\nunderstand, train, and guide [3].\\nThis raises a crucial question: How can we build agents who think and act\\nintelligently? How should we structure their ‘minds’ so that they can interpret\\ninformation, reason, plan effectively, and make decisions that we can trust?\\nBuilding on this vision of LLM agents as intelligent collaborators, this review\\nexplores and defines the architectural foundations that enable their autonomous\\nand effective performance in complex tasks [20].\\n1.2 Review Objective'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 1, 'page_label': '2'}, page_content='explores and defines the architectural foundations that enable their autonomous\\nand effective performance in complex tasks [20].\\n1.2 Review Objective\\nThe primary objective of this research is to review the design and implementation\\nof intelligent agents powered by large language models (LLMs) to improve the\\nexecution of complex automation tasks [13,14]. Specifically, the review focuses on\\nthe agents’ perception, memory, reasoning, planning, and execution capabilities.\\nThe review aims to accomplish this by pursuing the following particular goals:\\n1. Explore the options for perception systems, including multimodal LLMs and\\nimage processing tools, analyzing their contributions to interpreting visual\\ninputs for task execution.\\n2. Examine reasoning architectures, such as Chain-of-Thought (CoT) and Tree-\\nof-Thought (ToT), and their contributions to generating structured plans for\\ncomplex tasks, including how reflection enhances iterative problem solving.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 1, 'page_label': '2'}, page_content='of-Thought (ToT), and their contributions to generating structured plans for\\ncomplex tasks, including how reflection enhances iterative problem solving.\\n3. Explore and evaluate memory-augmented architectures, such as Retrieval-\\nAugmented Generation (RAG) and long-term memory systems, investigating\\neffective methods for information storage to enable practical and useful\\napplications.\\n4. Examine the available execution architectures, such as tool-based frameworks,\\nand code generation approaches, exploring their contributions to automating\\ntasks.\\n5. Finally, evaluate the complexity of implementation of each system solution\\nproposed.\\nTo achieve these objectives, some challenges need to be overcome.\\n1.3 Problem Statement\\nBuilding LLM agents to automate complex tasks can offer useful opportunities\\nbut also pose complex challenges [13,23,61]. Despite all the advances in LLMs,\\ndeveloping agents that perform well in various scenarios remains a significant'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 2, 'page_label': '3'}, page_content='Building Autonomous LLM Agents 3\\nchallenge [23]. The purpose of this study is to address these issues by review-\\ning each system’s implementation options, assessing their contributions, and\\ncontrasting various strategies.\\nBenchmarks such as OSworld [71], alongside studies on autonomous software\\nagents [13,15,16], reveal key limitations in multimodal agents, highlighting the\\nfollowing issues:\\n1. Difficulties in GUI grounding and operational knowledge:Agents\\nstruggle to accurately map screenshots to precise coordinates for their ac-\\ntions and lack deep understanding of basic graphical user interface (GUI)\\ninteractions and application-specific features.\\n2. Repetitive actions:Agents frequently predict repetitive actions, indicating\\na lack of progress or an inability to break out of loops.\\n3. Inability to handle unexpected window noise:Agents are not robust to\\nunexpected elements or changes in UI layout, such as unanticipated pop-up\\nwindows or dialog boxes.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 2, 'page_label': '3'}, page_content='3. Inability to handle unexpected window noise:Agents are not robust to\\nunexpected elements or changes in UI layout, such as unanticipated pop-up\\nwindows or dialog boxes.\\n4. Limitations in exploration and adaptability:Particularly for agents\\nequipped with modules like “Set-of-Mark” (SoM), it has been observed that\\nthey can constrain the agent’s action space, hindering exploration and adapt-\\nability to diverse tasks.\\n5. Significant performance gap with human capabilities:As reported on\\nthe OSworld website [43], humans achieve a task completion rate of more than\\n72.36%. In contrast, leading models reach approximately 42.9% completion\\n(as of June 2025), indicating a substantial gap with human performance.\\nTo address these challenges and guide the investigation of agent design, this\\nresearch presents a set of questions to explore the architectural components,\\nintegration strategies, and generalization capabilities of LLM-based agents.\\n1.4 Research Questions'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 2, 'page_label': '3'}, page_content='research presents a set of questions to explore the architectural components,\\nintegration strategies, and generalization capabilities of LLM-based agents.\\n1.4 Research Questions\\nTo guide this survey, we formulate the following research questions that structure\\nthe analysis of architectural foundations, subsystem design, and evaluation of\\nLLM based agents.\\n1. RQ1, Design space,What architectural options exist for the core subsys-\\ntems of LLM-based agents, perception, reasoning and planning, memory, and\\nexecution, and how can they be systematically organized for practitioner use?\\n2. RQ2, Integration,Which subsystem integration patterns enable reliable\\nclosed-loop autonomy in realistic software environments, for example, GUI\\nand web tasks that combine visual grounding with structured signals such as\\nDOM or accessibility trees [30,56]?\\n3. RQ3, Reasoning efficacy,How do reasoning strategies, for example, CoT,\\nToT,ReAct,andparallelplanning,suchasDPPMorMCTS-basedapproaches,'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 2, 'page_label': '3'}, page_content='DOM or accessibility trees [30,56]?\\n3. RQ3, Reasoning efficacy,How do reasoning strategies, for example, CoT,\\nToT,ReAct,andparallelplanning,suchasDPPMorMCTS-basedapproaches,\\naffect task success rate, efficiency, and cost?'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 3, 'page_label': '4'}, page_content='4 de Lamo et al.\\n4. RQ4, Memory impact,How do long-term and short-term memory mech-\\nanisms, for example, RAG and context management, influence accuracy,\\nrobustness to context length limits, and adaptation in long-horizon tasks?\\n5. RQ5, Failures and mitigation,What are the principal failure modes\\nin agentic settings, for example, hallucination, GUI misgrounding, repeti-\\ntive loops, and tool misuse, and which mitigation techniques, for example,\\nreflection, anticipatory reflection, SoM, and guardrails, are most effective?\\n6. RQ6, Evaluation and generalization,Which benchmarks and metrics are\\nappropriate for assessing these systems, for example, OSWorld, WebArena,\\nand Mind2Web [8,70,71], and to what extent do agents generalize across\\ntasks, applications, and interfaces?\\nBefore delving into these research questions, let us first explore the origins of\\nLLM-based agents.\\n2 Fundamentals\\n2.1 Background of LLMs\\nThe introduction of machine learning methods, particularly deep learning, brought'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 3, 'page_label': '4'}, page_content='LLM-based agents.\\n2 Fundamentals\\n2.1 Background of LLMs\\nThe introduction of machine learning methods, particularly deep learning, brought\\na significant shift by laying the groundwork for advanced modern AI models.\\nLarge language models (LLMs) are among the most significant developments.\\nTheir appearance represents a major breakthrough in AI’s ability to understand\\nand produce complex language, influencing the state of LLM-based agents today\\nand their future course.\\nA key technological advance in the development of LLMs has been the\\ntransformer architecture, distinguished by its “attention mechanism” [52]. This\\nmechanism allows LLMs to attend to different words in the input enabling them\\nto understand long-range dependencies [52]. This architectural shift, alongside\\ntheir training on vast datasets and the principles of generative AI, has enabled\\nLLMs to perform a wide range of tasks, including natural language processing'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 3, 'page_label': '4'}, page_content='their training on vast datasets and the principles of generative AI, has enabled\\nLLMs to perform a wide range of tasks, including natural language processing\\n(NLP), machine translation, vision applications, and question-answering.\\n2.2 From LLMs to LLM Agents\\nLLMs in their standard form have significant limitations due to their chatbot\\nnature. This restricts their effectiveness in real-world tasks. These models lack\\nlong-term memory, cannot autonomously interact with external tools, and struggle\\nto pursue goals in dynamic environments. Such shortcomings hinder their perfor-\\nmance in scenarios requiring sustained reasoning or multi-step workflows [61].\\nTo overcome these constraints, LLMs are guided to follow a reasoning path\\nand are provided with tools to interact with the environment that enables them\\nto function as autonomous agents. They are well-suited for dynamic tasks because\\nthey exhibit good planning skills, context adaptability, and they minimize human'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 3, 'page_label': '4'}, page_content='to function as autonomous agents. They are well-suited for dynamic tasks because\\nthey exhibit good planning skills, context adaptability, and they minimize human\\nintervention. Such agents offer a scalable and flexible solution by simulating\\nhuman-like team strategies and leveraging external tools [29].'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 4, 'page_label': '5'}, page_content='Building Autonomous LLM Agents 5\\nHowever, simply augmenting an LLM with modules, tools, or predefined steps\\ndoes not make it an agent, in any case, that would make it a workflow.\\n2.3 Workflows vs. Agents\\nMany people confuse workflows with agents, but while both enhance the ca-\\npabilities of large language models (LLMs), they are fundamentally different.\\nWorkflows are structured systems that enhance LLMs by enabling tool use,\\nenvironmental interaction, or access to long-term memory. However, they are\\nnot agents. Workflows perform well in controlled and predictable environments\\nwhere tasks are well defined and follow a fixed sequence of steps. In a workflow,\\nthe LLM follows a pre-established plan created by its designer, broken down\\ninto specific, sequential actions. This rigidity makes workflows highly effective\\nfor repetitive and structured tasks but limits their adaptability. If, during the\\nworkflow, the LLM faces an error, it often struggle to adjust, as they lack the'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 4, 'page_label': '5'}, page_content='for repetitive and structured tasks but limits their adaptability. If, during the\\nworkflow, the LLM faces an error, it often struggle to adjust, as they lack the\\nability to dynamically re-plan or adapt based on new information.\\nIn contrast, agents are far more versatile and autonomous. Agents are designed\\nto act according to the feedback from its environment. Rather than relying on\\na pre-set plan, agents generate their own strategies tailored to the task and\\ncontext, often using techniques like Chain-of-Thought reasoning or iterative\\nrefinement to break down complex problems. This adaptability allows agents to\\ndeal with unexpected challenges, bounce back from mistakes, and function well\\nin unpredictable environments [3].\\nTo understand how these agents achieve autonomy, we first explore their core\\ncomponents and their interconnections.\\n2.4 Constitution of an Agent\\nPerception SystemAn agent begins its interaction with the world through its'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 4, 'page_label': '5'}, page_content='components and their interconnections.\\n2.4 Constitution of an Agent\\nPerception SystemAn agent begins its interaction with the world through its\\nperception system. This component is responsible for capturing and processing\\ndata from the environment, such as images, sounds, or any other form of informa-\\ntion. Its task is to transform this information into meaningful representations that\\nthe LLM can understand and utilize, such as identifying objects or recognizing\\npatterns.\\nReasoning SystemThe reasoning system receives the task instructions along\\nwith the data from the perception system and formulates a plan that is broken\\ndown into distinct steps. It is also responsible for adjusting this plan based\\non environmental feedback and evaluating its own actions to correct errors or\\nimprove execution efficiency.\\nMemorySystemThememorysystemkeepstheknowledgethatisnotembedded\\nin the model’s weights. This includes everything from past experiences to relevant'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 4, 'page_label': '5'}, page_content='improve execution efficiency.\\nMemorySystemThememorysystemkeepstheknowledgethatisnotembedded\\nin the model’s weights. This includes everything from past experiences to relevant\\ndocuments and structured data stored in relational databases. The LLM uses\\nthis information to enhance the accuracy of its responses.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 5, 'page_label': '6'}, page_content='6 de Lamo et al.\\nAction SystemFinally, the action system is responsible for translating abstract\\ndecisions into concrete actions that impact the environment. This module ensures\\nthat the agent’s instructions are carried out in the real or simulated world,\\ncompleting the interaction cycle by executing what has been decided. This can\\ninvolve using a set of tools, such as calling APIs or writing code to execute mouse\\nmovements in a software environment [39].\\nFig.1.Key Components of an Agent’s LLM Architecture\\nHaving outlined the core components that enable an LLM agent’s autonomy,\\nwe now delve into a detailed exploration of the perception system.\\n3 Perception System\\nThe perception system of an LLM agent essentially acts as its “eyes and ears,”\\nconverting environmental stimuli into a format that the LLM can understand\\nand process. The complexity of the environment and the kinds of information\\nrequired determine the architecture. This challenge can be approached in four'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 5, 'page_label': '6'}, page_content='and process. The complexity of the environment and the kinds of information\\nrequired determine the architecture. This challenge can be approached in four\\nways: text-based, multimodal, information tree/structured data, and tool-based.\\n3.1 Text-Based Perception (Pure LLM)\\nThe simplest form in which the environment is described is purely in text. The\\nLLM receives and processes this text description. In this mode, the environment\\nprovides textual observations directly to the LLM’s prompt. This could be a\\ndescription of the current state, recent events, or results of actions taken. In this\\nenvironment, the perception system does not need to intervene.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 6, 'page_label': '7'}, page_content='Building Autonomous LLM Agents 7\\nThis approach offers low computational overhead for perception and integrates\\ndirectly with the LLM’s core capabilities. However, it is limited to environments\\nthat give the response to LLM interactions in text. This is practical for chats or\\ntext-driven simulations.\\n3.2 Multimodal Perception\\nAgents can process and integrate information from a variety of sources, mainly\\ntextual and visual (images, videos), thanks to multimodal perception. For agents\\nfunctioning in real-world or graphical user interfaces (GUIs), this capability is\\ncrucial. In the context of LLM agents, this is largely achieved through Vision-\\nLanguage Models (VLMs) and their more advanced successors, Multimodal Large\\nLanguage Models (MM-LLMs). These models aim to bridge the gap between\\nimages and words, allowing agents to understand and generate content across\\nboth modalities.\\nAlthough significant progress has been made in the extension of LLMs to'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 6, 'page_label': '7'}, page_content='images and words, allowing agents to understand and generate content across\\nboth modalities.\\nAlthough significant progress has been made in the extension of LLMs to\\nvision, it still has some challenges. For instance, most models still struggle with\\nprecise spatial relationships or accurate object counting without external aid [9].\\nRegardless of the specific training paradigm, a fundamental principle is the\\nlearning of a unified embedding space for vision and language. This means\\nthat both visual and textual data are converted into numerical representations\\n(embeddings) that can be processed and compared together by the model [34].\\nMM-LLMs represent a significant advancement, distinguished by their ap-\\nproach of augmenting powerful, off-the-shelf LLMs to support multimodal inputs\\nor outputs. Unlike VLMs, which primarily aim to align visual and linguistic\\nrepresentations, MM-LLMs leverage the inherent reasoning capabilities of a large'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 6, 'page_label': '7'}, page_content='or outputs. Unlike VLMs, which primarily aim to align visual and linguistic\\nrepresentations, MM-LLMs leverage the inherent reasoning capabilities of a large\\nlanguage model as their central processing unit. This enables them not only to\\nprocess and connect modalities but also to perform complex reasoning, planning,\\nand generation across a diverse range of multimodal tasks.\\nThe general architecture of MM-LLMs typically comprises a structured\\npipeline with distinct components [67]:\\n– Modality Encoder (ME):This component is responsible for encoding\\ninputs from various modalities, such as images, videos, or even audio and\\n3D data, to obtain corresponding features or embeddings. For visual inputs,\\nspecialized encoders like Convolutional Neural Networks (CNNs) or Vision\\nTransformers (ViT) are used to extract rich visual representations [34,45].\\n– Input Projector:This component aligns the encoded features from non-'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 6, 'page_label': '7'}, page_content='Transformers (ViT) are used to extract rich visual representations [34,45].\\n– Input Projector:This component aligns the encoded features from non-\\ntextual modalities (e.g., visual embeddings) with the text feature space of the\\nLLM. It acts as a bridge, transforming the visual embeddings into a format\\nthat the LLM can comprehend and integrate alongside textual inputs. This\\nprocessing ensures that the visual embeddings are effectively supplied to the\\nLLM, enabling the LLM to leverage its pre-trained linguistic knowledge for\\nmultimodal reasoning [34,50].\\n– LLM Backbone:This is the core reasoning engine. The processed and\\naligned multimodal representations (visual embeddings and textual features)'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 7, 'page_label': '8'}, page_content='8 de Lamo et al.\\nare fed to the LLM. The LLM processes these representations, answering\\nusing the semantic understanding of the inputs.\\n– Output Projector (for multimodal generation):For tasks requiring out-\\nputs in other modalities (e.g., generating images), this component maps signal\\ntoken representations from the LLM Backbone into features understandable\\nby a Modality Generator.\\n– Modality Generator (for multimodal generation):This component is\\ntasked with producing outputs in distinct modalities, such as synthesizing\\nimages using models like Latent Diffusion Models.\\nFig.2.Architecture of Multimodal Large Language Models (MM-LLMs) for Under-\\nstanding and Generation [67]\\nWhile the architectural components of MM-LLMs enable multimodal process-\\ning, their perceptual capabilities often require further enhancement to address\\nlimitations in visual understanding, as explored in the following subsection.\\nEnhancing Perception in MM-LLMsAs outlined in the paper “VCoder:'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 7, 'page_label': '8'}, page_content='limitations in visual understanding, as explored in the following subsection.\\nEnhancing Perception in MM-LLMsAs outlined in the paper “VCoder:\\nVersatile Vision Encoders for Multimodal Large Language Models” by Jain et al.\\n(2023) [28], traditional MM-LLM systems often face limitations in fundamental\\nvisual perception, such as accurately identifying or counting objects, and a\\ntendency to hallucinate non-existent entities.\\nA faster and more cost-effective way to enhance perception (rather than\\nimproving each individual component of an MM-LLM) is to use visual encoders.\\nThese encoders, which can be separate models, extract relevant information from\\nimages to help the MM-LLM interpret them more effectively. While this approach\\ndoesn’t match the performance gains of directly improving each component of\\nthe MM-LLM, it offers a practical trade-off by significantly improving results at\\na much lower computational and developmental cost. These are different ways to'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 7, 'page_label': '8'}, page_content='the MM-LLM, it offers a practical trade-off by significantly improving results at\\na much lower computational and developmental cost. These are different ways to\\nenhance visual perception with visual encoders:\\n– Segmentation and Depth Maps:VCoder enhances MM-LLM capabilities\\nthrough a specialized adaptive architecture and the integration of additional'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 8, 'page_label': '9'}, page_content='Building Autonomous LLM Agents 9\\nperception modalities. It functions as an adapter to a base MM-LLM, enabling\\nthe model to process “control inputs” such as segmentation maps (offering\\nfine-grained object and background information) and depth maps (providing\\nspatial relationship details). Information from these inputs is projected into\\nthe LLM’s embedding space via additional vision encoders [45].\\nFig.3.Usage of segmentation and depth maps for MM-LLM perception [28]\\n– Set-of-Mark Operation:To enhance the model’s ability to handle complex\\nvisual tasks, Set-of-Mark (SoM) operation provides a structured approach to\\nguide MM-LLMs in processing visual inputs. As seen in Fig. 4 set-of-mark\\nprocess consists in annotating images with explicit markers (e.g., bounding\\nboxes or labels) that highlight key regions or objects, enabling the model to\\nfocus on specific areas during reasoning. This technique improves the model’s\\nunderstanding of the image and task-specific performance [64].'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 8, 'page_label': '9'}, page_content='focus on specific areas during reasoning. This technique improves the model’s\\nunderstanding of the image and task-specific performance [64].\\nExperimental evidence presented in the papers [28,64] indicates that MM-\\nLLMs adapted with VCoder and SoM significantly outperform baseline models\\non object-level perception tasks, demonstrating improved counting accuracy and\\nreduced hallucination. This highlights the ongoing efforts to enhance the granular\\nperception capabilities of LLM-based agents.\\nWhile techniques like Set-of-Mark and VCoder enhance visual perception\\nthrough targeted annotations and prompting, structured data approaches, such\\nas Accessibility Tree and HTML utilization, offer alternative methods for robust\\nenvironmental interpretation, as explored in the following subsection.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 9, 'page_label': '10'}, page_content='10 de Lamo et al.\\nFig.4.Image with Set-of-Mark [64]\\n3.3 Information Tree/Structured Data Perception\\n– Accessibility Tree Utilization:OSCAR [56] utilizes an A11y tree gener-\\nated by the Windows API for representing GUI components, incorporating\\ndescriptive labels to facilitate semantic grounding.\\n– HTML Utilization:Meanwhile, DUALVCR [30] captures both the visual\\nfeatures of the screenshot and the descriptions of associated HTML elements\\nto obtain a robust representation of the visual screenshot.\\n3.4 Tool-based Perception\\nBeyond direct multimodal inputs and structured data retrieval, LLM-based agents\\ncan significantly enhance their perception capabilities through tool augmentation.\\nThis means utilizing external tools and APIs to enable the agent to gather,\\nprocess, and interpret data from a wider variety of sources, including real-world\\nsensors and specialized databases. The mechanism of integration typically involves'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 9, 'page_label': '10'}, page_content='process, and interpret data from a wider variety of sources, including real-world\\nsensors and specialized databases. The mechanism of integration typically involves\\nthe LLM generating specific tool calls based on its current understanding and\\ngoals, with the results from these tools being “fed back” into the LLM [44,47].\\nCategorizing Tools for PerceptionThe diverse landscape of external tools\\navailable to LLM agents can be broadly categorized based on the type of infor-\\nmation they help perceive:\\n– Web Search and Information Retrieval APIs:These tools allow agents\\nto access vast amounts of up-to-date information, facts, and specific data\\npoints from the internet. By issuing queries to search engines (e.g., Google\\nSearch API) or structured knowledge bases (e.g., Wikipedia API), agents can'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 10, 'page_label': '11'}, page_content='Building Autonomous LLM Agents 11\\nperceive real-time events, verify facts, or retrieve details beyond their training\\ndata cutoff. This helps the agent fill in missing environmental information and\\nis crucial for tasks requiring current affairs knowledge or factual accuracy [40,\\n44,47].\\n– Specialized APIs:Agents can use domain-specific APIs designed for specific\\ndata types. Examples include weather APIs (for perceiving current and\\nforecasted climatic conditions), stock market APIs (for real-time financial\\ndata), or scientific databases and literature APIs (for accessing specialized\\nresearch papers and experimental data). These tools enable agents to perceive\\nspecific information relevant to niche tasks [32,44], and can be implemented\\nas document-centric microservices for knowledge discovery [17].\\n– Sensor Integration (Conceptual via Intermediary Tools):While an\\nLLM agent does not directly interface with physical hardware sensors, its'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 10, 'page_label': '11'}, page_content='– Sensor Integration (Conceptual via Intermediary Tools):While an\\nLLM agent does not directly interface with physical hardware sensors, its\\nperception system can be augmented to interpret data originating from them.\\nThis is achieved through intermediary tools or services that convert raw\\nsensory data (e.g., temperature readings, GPS coordinates, accelerometer\\ndata) from real-world or simulated environments into a digestible format\\n(textual descriptions, structured data like JSON). This allows the agent to\\nperceive physical properties and spatial relationships of its environment,\\ncrucial for tasks in robotics or interactive simulations [2,7].\\n– Code Execution Tools:These tools enable agents to execute code for data\\nprocessing and calculations. By generating and executing code (e.g., Python\\nscripts via an interpreter), agents can perceive insights from raw data, such as\\nparsing complex log files, running statistical analyses on datasets, or querying'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 10, 'page_label': '11'}, page_content='scripts via an interpreter), agents can perceive insights from raw data, such as\\nparsing complex log files, running statistical analyses on datasets, or querying\\nlocal databases. This allows for dynamic and flexible data interpretation\\nbeyond simple text matching [10,42].\\nLet’s now explore how integrating the diverse perception system approaches\\nempowers an LLM agent to effectively handle tasks, as illustrated in a practical\\nexample.\\n3.5 Example of a Perception System in an LLM Agent\\nLet’s consider an LLM agent designed to automate tasks within a Graphical User\\nInterface (GUI), such as managing emails in a web-based application.\\nAlthough this could be easier to achieve using the email API, imagine a\\nscenario where the agent’s objective is to identify, classify, and, if necessary,\\nrespond to incoming company emails.\\nTo achieve this, the agent starts by capturing a screenshot of the email app. It\\nthen applies a Set-of-Mark operation using a visual encoder. This encoder draws'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 10, 'page_label': '11'}, page_content='respond to incoming company emails.\\nTo achieve this, the agent starts by capturing a screenshot of the email app. It\\nthen applies a Set-of-Mark operation using a visual encoder. This encoder draws\\na box on every interactive element on the screen, such as buttons or checkboxes\\nand stores the coordinates of each box. The output consists of the image with the\\nbounding boxes and a structured list describing each detected element, including\\nits text content (if any), a brief description, and its coordinates.\\nIn parallel, the agent retrieves the Accessibility Tree (A11y Tree) or the\\nHTML source of the page [15]. This tree provides a hierarchical representation of'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 11, 'page_label': '12'}, page_content='12 de Lamo et al.\\nGUI components, such as buttons, text fields, links, and list items—along with\\ntheir roles, labels, states (e.g., “unread”). Such data is typically extracted through\\nbrowser automation tools.\\nThe accessibility tree and the visual encoder output combine to create a\\nperception system. This system allows the agent to understand the interface: its\\nvisual layout, the semantics and roles of individual elements, and their spatial\\nstructure. When combined with the image understanding capabilities of a MM-\\nLLM, this perception system enables the agent to build a rich, actionable model\\nof the GUI environment.\\nDespite the robustness of this perception system, it has a number of drawbacks\\nand restrictions that can impact its performance and reliability.\\n3.6 Perception Challenges and Limitations\\nWhile significant progress has been made in empowering LLM agents with\\nadvanced perceptual capabilities, several critical challenges and limitations persist\\nacross all approaches:'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 11, 'page_label': '12'}, page_content='While significant progress has been made in empowering LLM agents with\\nadvanced perceptual capabilities, several critical challenges and limitations persist\\nacross all approaches:\\n– Hallucination:The tendency for models to “hallucinate” non-existent objects\\nor misinterpret visual cues remains a significant hurdle. This can lead to\\nagents making decisions based on incorrect interpretations, resulting in errors\\nor undesirable behavior [25].\\n– Latency in Inference Pipelines:Integrating complex perception modules,\\nespecially those involving multimodal processing or external tool calls, can\\nintroduce substantial latency. Real-world applications, particularly those\\nrequiring real-time interaction (e.g., robotics, dynamic GUI automation),\\ndemand rapid perceptual updates. The sequential nature of many perception\\npipelines, from raw data acquisition to final LLM interpretation, can create\\nbottlenecks, hindering the agent’s responsiveness.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 11, 'page_label': '12'}, page_content='pipelines, from raw data acquisition to final LLM interpretation, can create\\nbottlenecks, hindering the agent’s responsiveness.\\n– Context Window Limits:Large inputs, such as high-resolution images or\\nextensivestructureddata,cangenerateavastamountoftokensorembeddings.\\nEncoding and feeding this entire information into the LLM’s context window\\ncan quickly exceed its limitations [57].\\n– Data Collection:Training robust perception systems, particularly for mul-\\ntimodal or specialized domains, often requires large volumes of high-quality,\\nannotated data. The collection of this data can be costly and time-consuming.\\n– Computational Resources:High-fidelity perception, especially with mul-\\ntimodal inputs, requires high computational resources for both training\\nand inference. This can be a barrier for execution in resource-constrained\\nenvironments or for widespread adoption.\\nUltimately, the quality and fidelity of an LLM agent’s perception system'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 11, 'page_label': '12'}, page_content='and inference. This can be a barrier for execution in resource-constrained\\nenvironments or for widespread adoption.\\nUltimately, the quality and fidelity of an LLM agent’s perception system\\ndirectly affects the reasoning and planning modules. Therefore, continuous ad-\\nvancements in perception technologies are not merely improvements to one\\ncomponent, but fundamental enablers for building more intelligent, reliable, and\\ncapable LLM agents.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 12, 'page_label': '13'}, page_content='Building Autonomous LLM Agents 13\\nTable 1.Summary of Perception Approaches for LLM-Based Agents\\nModality Input Format Tool Dependencies Strengths Limitations\\nText-Based\\nPerception\\nPlain text\\ndescriptions\\nNone (relies on LLM’s\\nnative text processing)\\nLow computational\\noverhead; seamless\\nintegration with LLM; ideal\\nfor text-driven environments\\nLimited to text-only\\nenvironments; cannot\\nprocess visual or other\\nnon-textual data\\nMultimodal\\nPerception\\nText,\\nimage/video\\nembeddings,\\naudio transcripts\\nVision-Language Models\\n(e.g., CLIP, ViT),\\nMultimodal LLMs,\\npreprocessing tools (e.g.,\\nCNNs, ASR)\\nProcesses diverse data types;\\nsuitable for GUIs and\\nreal-world tasks; leverages\\nadvanced VLMs\\nHigh computational cost,\\nstruggles with precise\\nspatial tasks and requires\\nextensive training data\\nInformation\\nTree/Structured\\nData Perception\\nJSON, XML,\\ndatabase records,\\nA11y trees\\nParsers, database query\\ntools, accessibility\\nframeworks\\nPrecise semantic\\nunderstanding; efficient for'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 12, 'page_label': '13'}, page_content='Information\\nTree/Structured\\nData Perception\\nJSON, XML,\\ndatabase records,\\nA11y trees\\nParsers, database query\\ntools, accessibility\\nframeworks\\nPrecise semantic\\nunderstanding; efficient for\\nstructured environments like\\nGUIs or databases\\nLimited to environments\\nwith structured data and\\nrequires predefined schemas\\nor parsing logic\\nTool-Augmented\\nPerception\\nTool outputs\\n(text, JSON,\\nnumerical data)\\nExternal APIs, code\\ninterpreters, sensor\\ninterfaces, web search\\ntools\\nExtends perception to\\nreal-time and specialized\\ndata; highly flexible and\\ndynamic\\nDependent on tool\\navailability and reliability,\\ncomplex integration and\\nerror handling'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 13, 'page_label': '14'}, page_content='14 de Lamo et al.\\nHaving established how the perception system equips an LLM agent with a\\ncomprehensive understanding of the GUI environment, as summarized in the\\npreceding table, the next critical component is the reasoning system. This system\\nleverages the processed perceptual input to make informed decisions and execute\\ncomplex tasks.\\n4 Reasoning System\\n4.1 Task Decomposition\\nA key tactic for helping LLM agents solve complicated problems is task decom-\\nposition. This strategy divides the problem into smaller and easier-to-manage\\nsubtasks. This approach, akin to the “divide and conquer” algorithmic paradigm,\\nsimplifies the planning process. The procedure involves two main steps: first,\\nthe “decompose” step, where the complex task is broken into a set of subtasks;\\nand second, the “subplan” step, where for each subtask a plan is formulated [26].\\nThis systematic breakdown helps in navigating intricate real-world scenarios that'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 13, 'page_label': '14'}, page_content='and second, the “subplan” step, where for each subtask a plan is formulated [26].\\nThis systematic breakdown helps in navigating intricate real-world scenarios that\\nwould otherwise be challenging to address with a single-step planning process.\\nCurrent methodologies for task decomposition broadly fall into two categories:\\nDecomposition first and Interleaved decomposition [26]. Decomposition first\\nmethods, as seen in systems like HuggingGPT [48] and Plan-and-Solve [55],\\ninitially decompose the entire task into sub-goals and then proceed to plan\\nfor each sub-goal sequentially. HuggingGPT, for instance, explicitly instructs\\nthe LLM to break down multimodal tasks and define dependencies between\\nsubtasks [48]. A slightly modified version of the Decomposition first approach is\\nDPPM (Decompose, Plan in Parallel, and Merge). It addresses the limitations of\\nexisting planning methods, such as:\\n1. Handling heavy constraints\\n2. Carrying errors from the planning of previous steps'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 13, 'page_label': '14'}, page_content='DPPM (Decompose, Plan in Parallel, and Merge). It addresses the limitations of\\nexisting planning methods, such as:\\n1. Handling heavy constraints\\n2. Carrying errors from the planning of previous steps\\n3. Forgetting the main goal\\n4. Cohesion between subtasks\\nDPPM tackles these problems with the following methods: First, it decomposes\\nthe complex task into subtasks. Second, it generates subplans for each of these\\nsubtasks concurrently using individual LLM agents. This parallel planning allows\\neach agent to focus only on its assigned subtask, promoting independent work\\nand avoiding the cascading errors that can occur when subplans are sequentially\\ndependent. Finally, DPPM merges these independently generated local subplans\\ninto a coherent global plan [36]. Although this method can struggle to adapt\\nwell to unexpected environmental problems, this limitation can be mitigated by\\nreflecting on the plan after each execution step.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 13, 'page_label': '14'}, page_content='well to unexpected environmental problems, this limitation can be mitigated by\\nreflecting on the plan after each execution step.\\nIn contrast, interleaved decomposition methods, such as Chain-of-Thought\\n(CoT) [60] and ReAct [66], interleave the decomposition and subtask planning\\nprocess, revealing only one or two subtasks at a time based on the current\\nstate. This dynamic adjustment based on environmental feedback enhances fault'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 14, 'page_label': '15'}, page_content='Building Autonomous LLM Agents 15\\ntolerance, although excessively long trajectories in complex tasks can sometimes\\nlead to hallucinations or deviation from original goals [26].\\nFurther advancements in task decomposition and planning strategies include\\napproaches such as RePrompting and ReWOO. RePrompting involves checking if\\neach step of a plan meets necessary prerequisites before execution. If a step fails\\ndue to unmet prerequisites, a precondition error message is introduced, prompting\\nthe LLM to regenerate the plan with corrective actions [35]. ReWOO introduces\\na modular paradigm that decouples reasoning from external observations, where\\nagents first generate comprehensive plans and obtain observations independently,\\nthen combine them to derive final results [63].\\nFig.5.Comparison of different types of planning frameworks, including sequential\\ndecomposition-planning, interleaved decomposition-planning, and DPPM [36].\\n4.2 Multi-Plan Generation and Selection'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 14, 'page_label': '15'}, page_content='Fig.5.Comparison of different types of planning frameworks, including sequential\\ndecomposition-planning, interleaved decomposition-planning, and DPPM [36].\\n4.2 Multi-Plan Generation and Selection\\nDue to the inherent complexity of tasks and the uncertainty associated with\\nLLMs, a single plan generated by an LLM Agent may often be suboptimal or\\neven infeasible. To address this, multi-plan selection emerges as a more robust\\napproach, focusing on leading the LLM to explore multiple alternative plans\\nfor a given task [58]. This methodology involves two main stages: multi-plan\\ngeneration and optimal plan selection [26]. Multi-plan generation aims to create a\\ndiverse set of candidate plans, often by leveraging the uncertainty in the decoding\\nprocess of generative models.\\nThere are various strategies:'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 15, 'page_label': '16'}, page_content='16 de Lamo et al.\\n– Self-consistent CoT (CoT-SC):This approach generates various reasoning\\npaths and their corresponding answers using Chain of Thought (CoT), then\\nselects the answer with the highest frequency as the final output [58].\\n– Tree-of-Thought (ToT) and Graph of Thoughts (GoT):ToT gener-\\nates plans using a tree-like reasoning structure where each node represents\\nan intermediate “thought.” The selection of these steps is based on LLM\\nevaluations. Unlike CoT-SC, ToT queries LLMs for each reasoning step [65].\\nGraph-of-Thought (GoT) extends the tree-like reasoning structure of ToT\\nto graph structures. It supports arbitrary thought aggregation and allows\\nfor transformations of thoughts, leading to more powerful prompting strate-\\ngies [4].\\nFig.6.Schematic illustrating various approaches to problem solving with LLMs [65].\\n– LLM-MCTS and RAP:These methods leverage LLMs as a heuristic policy\\nfunction for the Monte Carlo Tree Search (MCTS). Multiple potential actions'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 15, 'page_label': '16'}, page_content='– LLM-MCTS and RAP:These methods leverage LLMs as a heuristic policy\\nfunction for the Monte Carlo Tree Search (MCTS). Multiple potential actions\\n(or plans) are obtained through multiple calls to the LLM during the MCTS\\nprocess [68]. RAP [24] specifically builds a world model to simulate potential\\nbenefits of different plans using MCTS to generate the final plan.\\nOnce a set of candidate plans is generated, the next step is plan selection,\\nwhere different search algorithms are employed [26]. Self-consistency, for instance,\\nutilizes a simple majority vote strategy to identify the most suitable plan [58].\\nMore advanced methods like Tree-of-Thought leverage tree search algorithms\\nsuch as conventional Breadth-First Search (BFS) and Depth-First Search (DFS)\\nfor expansion and selection, evaluating multiple actions to choose the optimal\\none [65]. Similarly, LLM-MCTS and RAP adopt tree structures to facilitate\\nmulti-plan searches using the MCTS algorithm [24]. The scalability of multi-'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 15, 'page_label': '16'}, page_content='one [65]. Similarly, LLM-MCTS and RAP adopt tree structures to facilitate\\nmulti-plan searches using the MCTS algorithm [24]. The scalability of multi-\\nplan selection is a significant advantage, allowing for a broader exploration of\\nsolutions within expansive search spaces. However, this comes with trade-offs like'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 16, 'page_label': '17'}, page_content='Building Autonomous LLM Agents 17\\nincreased computational demands. Furthermore, the reliance on LLMs for plan\\nevaluation introduces challenges regarding their performance in ranking tasks\\nand the potential for randomness due to the stochastic nature of LLMs, which\\ncan affect the consistency and reliability of chosen plans [26].\\nWhile multi-plan selection enables LLM agents to explore and evaluate multi-\\nple potential solutions prior to execution, the reasoning system is further enhanced\\nby the process of reflection. This mechanism allows agents to evaluate their ac-\\ntions and outcomes after the execution, encouraging continuous improvement\\nand adaptability in dynamic environments.\\n4.3 Reflection\\nReflection, in the context of LLM agents, refers to the agent’s ability to critically\\nevaluate its own past actions, reasoning, and outcomes, and then use these\\ninsights to improve its future performance. This allows agents to learn from their'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 16, 'page_label': '17'}, page_content='evaluate its own past actions, reasoning, and outcomes, and then use these\\ninsights to improve its future performance. This allows agents to learn from their\\nmistakes or inefficiencies without human intervention.\\nKey characteristics of reflection include:\\n– Self-Evaluation:The agent examines its completed (or ongoing) task, its\\ngenerated plans, and the results of its actions. This often involves comparing\\nactual and expected outcomes.\\n– Error Detection and Analysis:Identifying where things went wrong,\\nwhy a plan failed, or where the reasoning failed. This can be due to misun-\\nderstandings of the prompt, incorrect tool usage, logical inconsistencies, or\\nenvironmental changes. Papers like [49] and [38] exemplify this capability,\\nwhere agents analyze their own outputs or execution traces to pinpoint issues.\\n– Correction and Improvement:Based on the analysis, the agent gener-\\nates actionable insights. This might involve modifying its planning strategy,'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 16, 'page_label': '17'}, page_content='– Correction and Improvement:Based on the analysis, the agent gener-\\nates actionable insights. This might involve modifying its planning strategy,\\ncorrecting its reasoning process, learning better ways to use tools, updating\\nits “memory” or state [49], or generating a revised plan or a new set of\\nactions [6,38].\\n– Goal-Driven Reflection:Agents can reflect not just on errors, but also on\\nefficiency or completeness, aiming to optimize their path to the goal even if\\nno explicit error occurred.\\nBuilding on the conceptual framework of reflection and its key characteristics,\\nwe now explore the practical steps and components required to implement an\\neffective reflection system in LLM agents.\\nHow to Implement a Reflection System:A Reflection system, as described in\\nthe paper “Reflection: Language Agents with Verbal Reinforcement Learning,” [49]\\nis a framework designed to improve the performance of language agents through'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 16, 'page_label': '17'}, page_content='the paper “Reflection: Language Agents with Verbal Reinforcement Learning,” [49]\\nis a framework designed to improve the performance of language agents through\\nlinguistic feedback rather than traditional weight updates. It operates iteratively,\\nallowing an agent to learn from its past mistakes by writing the feedback and'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 17, 'page_label': '18'}, page_content='18 de Lamo et al.\\nstoring and using these reflections in the next iterations. Here’s a brief explanation\\nof how to implement such a system:\\nCore Components:\\n– Actor:This is typically a LLM that generates text and actions based on the\\ncurrent state observations and its memory.\\n– Evaluator:This component assesses the quality of the Actor’s generated\\noutputs. It takes a complete trajectory (sequence of actions and observations)\\nand computes a reward score. Evaluation can be based on exact match\\ngrading, predefined heuristics, or even another LLM instance.\\n– Self-Reflection Model:Another LLM serves as the self-reflection model\\nand is responsible for generating verbal self-reflections. Given a sparse reward\\nsignal (e.g., success/fail) and the current trajectory, it produces nuanced and\\nspecific feedback.\\nThe paper “DEVIL’S ADVOCATE: Anticipatory Reflection for LLM\\nAgents” [53] introduces a distinct perspective: Anticipatory Reflection. This'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 17, 'page_label': '18'}, page_content='specific feedback.\\nThe paper “DEVIL’S ADVOCATE: Anticipatory Reflection for LLM\\nAgents” [53] introduces a distinct perspective: Anticipatory Reflection. This\\nconsists of the agent proactively reflecting on potential failures and considering\\nalternative remedies before executing an action, essentially acting as a “devil’s\\nadvocate” to challenge its own proposed steps. This front-loaded introspection\\nenhances consistency and adaptability by allowing the agent to anticipate and\\nmitigate challenges, improving its ability to navigate complex tasks effectively.\\n4.4 Example of a Reasoning System\\nA reasoning system can be developed by integrating some of the features men-\\ntioned above. Its core mechanism could be DPPM (Decompose, Plan in Parallel,\\nand Merge).\\nFirst, the agent would decompose the main task into smaller subtasks. Then,\\nin separate calls to an LLM, different planning options would be generated for each'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 17, 'page_label': '18'}, page_content='and Merge).\\nFirst, the agent would decompose the main task into smaller subtasks. Then,\\nin separate calls to an LLM, different planning options would be generated for each\\nsubtask. While generating these options, the LLM would consider potential issues\\nthat might arise during the execution of each subtask. Based on these anticipated\\nproblems, it would propose alternative approaches to either solve or avoid them.\\nThis process combines ideas from Tree-of-thought and the Anticipatory Reflection\\nof the “DEVIL’S ADVOCATE” paper mentioned before.\\nFollowing the Merge step in DPPM, the agent would integrate the different\\nsubtask plans into a final, coherent plan to accomplish the overall goal. To do this,\\nit would explore various combinations of the subtask options, ensuring that the\\nresulting plan is logically consistent and that all subplans contribute meaningfully\\ntoward completing the main task.\\nAfterthefinalplanisconstructed,itwouldbedividedintogroupsofexecutable'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 17, 'page_label': '18'}, page_content='resulting plan is logically consistent and that all subplans contribute meaningfully\\ntoward completing the main task.\\nAfterthefinalplanisconstructed,itwouldbedividedintogroupsofexecutable\\nsteps. As the agent carries out each group of steps, it would receive feedback from\\nthe environment. This feedback would be processed by a reflection mechanism,\\nwhich would determine the current scenario:\\n1. Successful execution: The actions produced the expected result, so the agent\\ncontinues with the next group of steps.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 18, 'page_label': '19'}, page_content='Building Autonomous LLM Agents 19\\n2. Minor error: The actions were close but not entirely accurate (e.g., the agent\\nmissed clicking a button because the coordinates were slightly off). In this\\ncase, the steps would be adjusted and corrected accordingly.\\n3. Execution failure: The plan cannot be completed as-is (e.g., the button to be\\nclicked does not exist). Here, the agent must reflect on whether the issue lies\\nwithin the specific subplan or if the entire plan needs to be reconsidered. If\\nonly the subplan is flawed, a new one would be generated. If the problem\\nis more fundamental, the entire planning process would restart from the\\nbeginning.\\nFig.7.Flowchart of a Reasoning System Using Decompose, Plan, and Merge (DPPM)\\napproach with a reflection system'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 19, 'page_label': '20'}, page_content='20 de Lamo et al.\\nHaving illustrated how a single LLM agent can leverage a reasoning system\\nlike DPPM, combined with reflection, we now explore how multi-agent sys-\\ntems distribute these processes across specialized components to achieve greater\\nscalability and efficiency.\\n4.5 Multi-Agent Systems\\nExpanding on the idea of multi-agent systems, a single agent can be made up\\nof different specialized “experts,” each of whom focuses on a distinct aspect of\\nthe interaction or reasoning. This modularity enables specialization at each step,\\nincreasing its capabilities and robustness [5]. Here are some examples of such\\nuseful experts that an LLM agent could integrate:\\n– Planning Expert:This expert focuses on strategic thinking and task\\ndecomposition. Its role is to break down complex objectives into a series of\\nmanageable subtasks. This aligns with the actor component discussed in the\\nreflection system, where agents perform reasoning and planning to undertake\\ncomplex tasks [33].'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 19, 'page_label': '20'}, page_content='manageable subtasks. This aligns with the actor component discussed in the\\nreflection system, where agents perform reasoning and planning to undertake\\ncomplex tasks [33].\\n– Reflection Expert:It is dedicated to evaluating plans, responses, and\\noverall performance. This aligns with the evaluator component discussed in\\nthe reflection system [33].\\n– Error Handling Expert:Specifically focused on identifying, diagnosing,\\nand suggesting recovery strategies for errors. This expert could analyze logs,\\nidentify common failure patterns, and propose fixes. For example, it could\\npropose to scroll down if an item is not found in a webpage [51]. It can also\\nsupport self-healing behaviors in adaptive architectures [19].\\n– Memory Management Expert:Responsible for handling the agent’s\\nmemory. This expert ensures that relevant information is retrieved efficiently\\nand that the agent’s context is maintained effectively, which is a critical\\nchallenge in LLM-based multi-agent systems [23,33].'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 19, 'page_label': '20'}, page_content='and that the agent’s context is maintained effectively, which is a critical\\nchallenge in LLM-based multi-agent systems [23,33].\\n– Action Expert:This expert knows how to translate plans into concrete\\ninteractions with the environment. It’s skilled in generating the necessary\\ncommands or API calls to interact with external tools, web interfaces, or\\nother systems. For example, it is responsible for creating the move and click\\nmouse movements in benchmarks like OSWorld. [21,33,71].\\nIn addition to the experts mentioned above, there could be other helpful\\nexperts depending on the use case. For example, there could be a Coding Ex-\\npert for generating, debugging, and optimizing code [51]; an Information Re-\\ntrieval Expert for efficiently acquiring knowledge from external sources [21,33];\\na Human-Computer Interaction (HCI) Expert for optimizing user experience\\nthrough adaptive and intuitive communication; a Constraint Satisfaction Expert'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 19, 'page_label': '20'}, page_content='a Human-Computer Interaction (HCI) Expert for optimizing user experience\\nthrough adaptive and intuitive communication; a Constraint Satisfaction Expert\\nfor ensuring adherence to predefined rules, constraints, and assurances in vari-\\nous applications [21], who can also leverage existing model-driven verification\\ntools [12,18]; and a Security Expert for mitigating vulnerabilities, promoting\\nsecure practices, and monitoring risks in multi-agent interactions [21,51].'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 20, 'page_label': '21'}, page_content='Building Autonomous LLM Agents 21\\nHaving outlined some possible experts within multi-agent systems, we now\\nturn to the practical process of designing and building these experts.\\n4.6 How to Build an Expert\\nBuilding an “expert” within an LLM agent involves a combination of design\\nprinciples and leveraging the capabilities of Large Language Models\\nDefine the Expert’s Role and Scope (Profile and Specialization). The first\\nstep is to precisely define the “distinctive attributes and roles” [51] of your expert.\\nThis involves:\\n– Clear Specialization:What specific task, domain, or reasoning capability\\nwill this expert excel at? (e.g., planning, code generation, error handling).\\n– Input and Output:What kind of information does this expert take as\\ninput, and what kind of output does it produce?\\n– Boundaries:What are the limitations of its expertise? When should other\\nexperts be consulted or take over? [33].\\nEquip with KnowledgeAn expert’s effectiveness hinges on its specialized'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 20, 'page_label': '21'}, page_content='– Boundaries:What are the limitations of its expertise? When should other\\nexperts be consulted or take over? [33].\\nEquip with KnowledgeAn expert’s effectiveness hinges on its specialized\\nknowledge. This can be achieved by:\\n– Targeted Prompting:Crafting precise and detailed prompts to steer the\\nLLM toward performing as the expert, incorporating specific prompting\\ntechniques such as Chain-of-Thought to enhance its reasoning process.\\n– Fine-tuning (if applicable):For highly specialized tasks, fine-tuning a\\nbase LLM on a dataset relevant to the expert’s domain can enhance its\\nperformance.\\n– External Knowledge Bases:Integrating the expert with external tools or\\ndatabases that provide specific, up-to-date, or proprietary knowledge relevant\\nto its role [21].\\n– Memory Integration:The expert may have access to its memory (short-\\nterm context and long-term knowledge) which can store past experiences or\\nknowledge relevant to its task [23,33].'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 20, 'page_label': '21'}, page_content='– Memory Integration:The expert may have access to its memory (short-\\nterm context and long-term knowledge) which can store past experiences or\\nknowledge relevant to its task [23,33].\\nWith the methodology for crafting specialized experts established, the follow-\\ning example illustrates how these components collaborate within a multi-agent\\nframework.\\nExample of a Multi-agent SystemFirst, the planning expert decomposes the\\nmain task into subplans. This expert is also responsible for avoiding infinite loops\\nor repeated attempts if problems occur. Additionally, it collaborates with the\\nconstraint satisfaction expert to ensure that no constraints are violated during\\nplanning.\\nNext, the execution expert generates the specific actions to be performed in\\nthe environment. If any tools are required, it consults the tool expert to determine'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 21, 'page_label': '22'}, page_content='22 de Lamo et al.\\nwhich tools to use and how to use them. If executable code is needed beyond\\nbasic actions, the coding expert is called upon to produce it.\\nOnce actions are executed, feedback from the environment is received and\\nprocessed by the reflection expert, which works together with the error handling\\nexpert to diagnose issues and propose solutions. Based on this diagnosis, the\\nreflection expert decides how to proceed.\\nTo improve its recommendations, the memory expert retrieves past experiences\\nor successful workflows related to similar tasks. This knowledge is used to inform\\nand enhance the next steps proposed to the planning or execution experts.\\nFig.8.Example of the communication between agents in a multi-agent system'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 22, 'page_label': '23'}, page_content='Building Autonomous LLM Agents 23\\nTable 2.Key Components and Techniques for the Reasoning System (Part 1)\\nComponent Description Key Techniques/Approaches Advantages Challenges/Limitations\\nTask\\nDecomposition\\nBreaks down complex\\ntasks into manageable\\nsubtasks to simplify\\nplanning and\\nexecution.\\n-Sequential Decomposition: Divides\\ntasks into sequential subgoals and plans\\n(e.g., Divide-and-Conquer).\\n-Interleaved Decomposition:\\nDynamically adjusts subtasks based on\\nfeedback (e.g., Chain-of-Thought [CoT],\\nReAct).\\n-DPPM (Decompose, Plan in\\nParallel, Merge): Decomposes tasks,\\nplans subtasks concurrently, and merges\\ninto a coherent global plan.\\n- Simplifies complex\\nproblem-solving.\\n- DPPM reduces\\ncascading errors via\\nparallel planning.\\n- Interleaved methods\\nenhance fault\\ntolerance.\\n- DPPM struggles with\\nunexpected environmental\\nchanges.\\n- Interleaved methods may\\nlead to hallucinations or\\ndeviation in long tasks.\\nMulti-Plan\\nGeneration and\\nSelection\\nGenerates multiple\\ncandidate plans and'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 22, 'page_label': '23'}, page_content='unexpected environmental\\nchanges.\\n- Interleaved methods may\\nlead to hallucinations or\\ndeviation in long tasks.\\nMulti-Plan\\nGeneration and\\nSelection\\nGenerates multiple\\ncandidate plans and\\nselects the optimal one\\nto address task\\nuncertainty.\\n-Self-consistent CoT (CoT-SC):\\nGenerates multiple reasoning paths and\\nselects the most frequent answer.\\n-Tree-of-Thought (ToT): Uses tree-like\\nreasoning structures for plan generation.\\n-Graph-of-Thoughts (GoT): Extends\\nToT with graph structures for flexible\\naggregation.\\n-LLM-MCTS and RAP: Use Monte\\nCarlo Tree Search for plan generation and\\nselection.\\n- Explores diverse\\nsolutions for robust\\nplanning.\\n- Scalable for\\ncomplex tasks with\\nlarge search spaces.\\n- High computational\\ndemands.\\n- Stochastic nature of LLMs\\nmay affect plan consistency.\\n- Challenges in ranking and\\nevaluating plans.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 23, 'page_label': '24'}, page_content='24 de Lamo et al.\\nTable 3.Key Components and Techniques for the Reasoning System (Part 2)\\nComponent Description Key Techniques/Approaches Advantages Challenges/Limitations\\nReflectionAllows agents to\\nevaluate actions\\npost-execution,\\nidentify errors, and\\nimprove future\\nperformance.\\n-Self-Evaluation: Compares actual vs.\\nexpected outcomes.\\n-Error Detection and Analysis:\\nIdentifies and analyzes errors (e.g.,\\nincorrect tool usage, logical flaws).\\n-Correction and Improvement:\\nAdjusts plans or strategies based on\\nanalysis.\\n-Anticipatory Reflection (DEVIL’S\\nADVOCATE): Proactively considers\\npotential failures before execution.\\n- Enables learning\\nfrom mistakes\\nwithout human\\nintervention.\\n- Enhances\\nadaptability and\\nefficiency.\\n- Anticipatory\\nreflection improves\\nconsistency.\\n- Requires robust feedback\\nmechanisms.\\n- May be limited by the\\nagent’s ability to accurately\\nself-evaluate.\\nMulti-Agent\\nSystems\\nDistributes reasoning\\ntasks across\\nspecialized “experts”\\nfor scalability and\\nefficiency.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 23, 'page_label': '24'}, page_content='mechanisms.\\n- May be limited by the\\nagent’s ability to accurately\\nself-evaluate.\\nMulti-Agent\\nSystems\\nDistributes reasoning\\ntasks across\\nspecialized “experts”\\nfor scalability and\\nefficiency.\\n-Planning Expert: Handles task\\ndecomposition and strategic planning.\\n-Reflection Expert: Evaluates plans and\\nsuggests improvements.\\n-Error Handling Expert: Diagnoses\\nand proposes fixes for runtime errors.\\n-Others: Includes Memory Management,\\nAction, Coding, Information Retrieval,\\nDialogue Management, HCI, Constraint\\nSatisfaction, and Security Experts.\\n- Enhances\\nmodularity and\\nrobustness.\\n- Leverages\\nspecialized expertise\\nfor complex tasks.\\n- Improves scalability\\nthrough division of\\nlabor.\\n- Requires careful\\ncoordination between\\nexperts.\\n- Potential for increased\\ncomplexity in system design.\\n- Security risks in\\nmulti-agent interactions.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 24, 'page_label': '25'}, page_content='Building Autonomous LLM Agents 25\\nHaving explored how reasoning systems enable LLM agents to plan, reflect,\\nand collaborate on complex tasks, we now consider the memory system, which\\nprovides the critical foundation for retaining and applying past experiences to\\ninform and enhance these reasoning processes.\\n5 Memory System\\nThe memory system empowers LLM agents to manage information across varying\\ntime scales, with long-term memory anchoring sustained knowledge retention\\nwhile short-term memory facilitates immediate contextual awareness.\\n5.1 Long-term memory\\nLong-term memory in LLM agents is crucial for sustained interaction and for\\nthe models to evolve and adapt over time. It allows agents to store relevant\\npast memories and learn information from previous interactions. It also enables\\nthe agent to retain knowledge apart from its pre-trained knowledge. There are\\ndifferent ways of implementing it:\\n– Embodied Memory:In the context of LLMs, “embodied memory” often'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 24, 'page_label': '25'}, page_content='the agent to retain knowledge apart from its pre-trained knowledge. There are\\ndifferent ways of implementing it:\\n– Embodied Memory:In the context of LLMs, “embodied memory” often\\nrefers to the idea that an agent’s experiences and learned behaviors become\\ningrained directly within its model parameters (weights) through continuous\\nlearning processes like fine-tuning. Unlike external memory systems, this type\\nof memory is build into the model itself. When an LLM is fine-tuned on new\\ndata, it adjusts its weights, effectively encoding new “facts” or “experiences”\\ndirectly into its neural network. This causes the model to act in ways similar\\nto what it has learned from these experiences [62].\\n– RAG:Retrieval-Augmented Generation (RAG) is a technique that enhances\\nLLMs by using external knowledge to improve the accuracy of its responses.\\nIt operates in two main phases: retrieval and augmentation. Using a query, a\\nretriever component first looks through an external knowledge base (often'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 24, 'page_label': '25'}, page_content='It operates in two main phases: retrieval and augmentation. Using a query, a\\nretriever component first looks through an external knowledge base (often\\nindexed by vector embeddings) to locate relevant documents. This gives the\\nLLM access to updated and precise information that might not be encoded\\nin its training data or within its immediate context window.\\nOnce the relevant information is retrieved, it is added to the LLM context\\nalongside the original query. This augmented input enables the LLM to gener-\\nate responses that are based on company files or personal documents making\\nthe response precise for the specific use case and reducing the likelihood\\nof “hallucinations” [31].\\n– SQL Database:SQL databases are used to store structured knowledge, such\\nas information about employees, orders, or other data that can be stored in a\\ntable. By converting natural language queries into SQL queries, text-to-SQL\\ntechniques facilitate reliable database interaction. Transformer-based models'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 24, 'page_label': '25'}, page_content='table. By converting natural language queries into SQL queries, text-to-SQL\\ntechniques facilitate reliable database interaction. Transformer-based models\\nare especially well-suited for producing intricate SQL queries because of their\\nattention mechanism [72].'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 25, 'page_label': '26'}, page_content='26 de Lamo et al.\\n5.2 Short-term memory\\nShort-term memory in LLM agents is analogous to the input information main-\\ntained within the context window, which acts as a temporary workspace [54].\\nRegardless of whether it’s for long-term retention or immediate contextual\\nawareness, the memory module’s effectiveness hinges on what kind of data to\\nstore.\\n5.3 What Kind of Data to Store\\nThe memory module within an LLM agent’s architecture is designed to store\\ndiverse types of information perceived from its environment and interactions.\\nThis stored data is then used to make better decisions, enabling the agent to\\naccumulate experiences, evolve, and behave in a more consistent and effective\\nmanner.\\n– Experiences:It is beneficial to store records of both successful and failed\\ntasks. Research has indicated that even failed experiences, when appropriately\\nlogged and distinguished as such, can be valuable. By explicitly noting a “failed'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 25, 'page_label': '26'}, page_content='tasks. Research has indicated that even failed experiences, when appropriately\\nlogged and distinguished as such, can be valuable. By explicitly noting a “failed\\nexperience,” LLMs can learn to avoid repeating similar mistakes in the future.\\nThis continuous learning from past interactions, including the identification\\nof “invalid action filtering,” contributes to the agent’s robust development and\\nability to adapt [1,22]. To store an experience, you capture a task’s natural\\nlanguage instruction (e.g., “Who ordered order 0130?”) and the sequence\\nof steps taken to solve it, where each step includes the agent’s observation\\nof the environment (e.g., “The current page shows order 0130”) and the\\naction performed (e.g., click(“126”) or stop()). This data, structured as an\\nexperience with the instruction and a trajectory of observation-action pairs,\\nis saved in a storage system like a database or a JSON file within a collection'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 25, 'page_label': '26'}, page_content='experience with the instruction and a trajectory of observation-action pairs,\\nis saved in a storage system like a database or a JSON file within a collection\\nof experiences. This format ensures that the experience is retrievable for\\nlater use, such as inducing a workflow with a summarized description and\\ngeneralized steps, which can then be integrated into the agent’s memory to\\nguide future tasks [59].\\n– Procedures:LLM agents can learn reusable task workflows from past expe-\\nriences to guide future actions, similar to humans. Agent Workflow Memory\\n(AWM) is a method that induces commonly reused routines (workflows) from\\ntraining examples and then selectively provides these workflows to the agent\\nto guide subsequent generations [59].\\n– Knowledge:This category encompasses external information received as\\nfacts, such as data from articles, company-specific information, details about\\nmachinery, and internal company rules [11], including document-based dis-'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 25, 'page_label': '26'}, page_content='facts, such as data from articles, company-specific information, details about\\nmachinery, and internal company rules [11], including document-based dis-\\ncovery pipelines in microservices architectures [17].\\n– User information:Beyond just user preferences, this includes personal\\ninformation that the user has supplied, such as details about their past activ-\\nities (e.g., where they spent the last Christmas) or background (e.g., where'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 26, 'page_label': '27'}, page_content='Building Autonomous LLM Agents 27\\ntheir parents are from). Mechanisms like MemoryBank aim to comprehend\\nand adapt to a user’s personality over time by synthesizing information from\\nprevious interactions, which inherently involves storing and utilizing these\\npersonal details [69].\\nWhile defining what kind of data to store is crucial for an LLM agent’s\\neffectiveness, the utility and management of this stored information are inherently\\nsubject to several limitations.\\n5.4 Limitations\\n– Context Window:Large Language Models (LLMs) operate with a funda-\\nmental constraint known as the “context window” or “context length.” This\\nrefers to the maximum amount of text (measured in “tokens,” which can\\nbe words, parts of words, or punctuation) that an LLM can process and\\nconsider at any one time when generating a response or performing a task.\\nThe primary impact of a limited context window is that LLMs cannot directly\\nintegrate or utilize all information in very long sequences. The easiest way to'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 26, 'page_label': '27'}, page_content='The primary impact of a limited context window is that LLMs cannot directly\\nintegrate or utilize all information in very long sequences. The easiest way to\\novercome this is to truncate large texts or summarize them [57].\\n– Memory Duplication:When storing information in memory, a potential\\nissue is handling data that is similar to existing records. Various methods have\\nbeen developed to integrate new and previous records to address this “Mem-\\nory Duplication” problem. For instance, in one approach, successful action\\nsequences related to the same sub-goal are stored in a list. Once this list\\nreaches a size of five, all sequences within it are condensed into a unified plan\\nsolution using LLMs, and the original sequences are then replaced with this\\nnewly generated one. Another method aggregates duplicate information by\\naccumulating counts, thereby avoiding redundant storage [54].'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 27, 'page_label': '28'}, page_content='28 de Lamo et al.\\nTable 4.Memory Components for LLM-Based Agents (Part 1)\\nComponent Description Key Techniques/Approaches Advantages Challenges/Limitations\\nLong-term\\nMemory\\nStores knowledge for\\nsustained retention,\\nenabling agents to\\nrecall past\\nexperiences and\\nsynthesize\\ninformation from\\nprevious interactions.\\n-Embodied Memory: Experiences are\\ningrained in the model’s parameters\\nthrough continuous learning (e.g.,\\nfine-tuning).\\n-Retrieval-Augmented Generation\\n(RAG): Retrieves relevant documents\\nfrom an external knowledge base using\\nvector embeddings to enhance responses.\\n-SQL Database: Stores structured data\\n(e.g., employee or order details) accessible\\nvia text-to-SQL queries generated by\\nLLMs.\\n- Enables persistent\\nknowledge retention.\\n- RAG reduces\\nhallucinations by\\ngrounding responses\\nin verifiable sources.\\n- SQL databases\\nsupport structured,\\nqueryable data\\naccess.\\n- Fine-tuning for embodied\\nmemory is computationally\\nexpensive.\\n- RAG requires efficient\\nindexing and retrieval\\nsystems.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 27, 'page_label': '28'}, page_content='- SQL databases\\nsupport structured,\\nqueryable data\\naccess.\\n- Fine-tuning for embodied\\nmemory is computationally\\nexpensive.\\n- RAG requires efficient\\nindexing and retrieval\\nsystems.\\n- Text-to-SQL generation\\nmay struggle with complex\\nqueries or dependencies.\\nShort-term\\nMemory\\nActs as a temporary\\nworkspace within the\\nLLM’s context\\nwindow, holding\\nimmediate contextual\\ninformation for\\nongoing tasks.\\n-Context Window Management:\\nMaintains recent conversational or input\\ndata within the transformer’s limited\\ncontext window.\\n-Chunking and Summarization:\\nBreaks down large inputs into manageable\\npieces and condenses essential information\\nto fit within the context window.\\n- Facilitates\\nimmediate contextual\\nawareness.\\n- Chunking and\\nsummarization\\nprevent information\\nloss in long\\nsequences.\\n- Limited by context\\nwindow size, leading to\\ntruncation of older data.\\n- Summarization may omit\\ncritical details if not\\ncarefully designed.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 28, 'page_label': '29'}, page_content='Building Autonomous LLM Agents 29\\nTable 5.Memory Components for LLM-Based Agents (Part 2)\\nComponent Description Key Techniques/Approaches Advantages Challenges/Limitations\\nData Storage\\nTypes\\nDefines the types of\\ninformation stored to\\nsupport agent\\nfunctionality.\\n-Procedures (Agent Workflow\\nMemory - AWM): Stores reusable task\\nworkflows derived from past experiences or\\nqueries to guide future actions.\\n-Knowledge: Includes external facts (e.g.,\\narticles, company rules) for\\ncontext-specific responses.\\n-User Information: Stores personal user\\ndetails (e.g., preferences, past activities)\\nvia systems like MemoryBank for\\npersonalized responses.\\n- Workflows improve\\nefficiency by reusing\\nsuccessful routines.\\n- External knowledge\\nenhances response\\naccuracy.\\n- User information\\nsupports\\npersonalized\\ninteractions.\\n- Managing diverse data\\ntypes requires robust\\nstorage systems.\\n- Privacy concerns with\\nstoring user information.\\n- Risk of outdated or\\nirrelevant knowledge\\naffecting performance.\\nMemory'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 28, 'page_label': '29'}, page_content='interactions.\\n- Managing diverse data\\ntypes requires robust\\nstorage systems.\\n- Privacy concerns with\\nstoring user information.\\n- Risk of outdated or\\nirrelevant knowledge\\naffecting performance.\\nMemory\\nManagement\\nIssues\\nAddresses challenges\\nin storing and\\nretrieving information\\nefficiently.\\n-Memory Duplication: Consolidates\\nsimilar records (e.g., combining successful\\naction sequences into a unified plan or\\naggregating counts).\\n- Reduces\\nredundancy and\\nstorage inefficiency.\\n- Duplication consolidation\\nmay lose nuanced details.\\n- FIFO overwriting risks\\nlosing valuable older data.\\n- Requires careful design to\\nbalance storage and\\nretrieval efficiency.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 29, 'page_label': '30'}, page_content='30 de Lamo et al.\\nWith its robust memory system supporting processed observations and for-\\nmulated plans, an LLM agent’s operational flow then progresses to the execution\\nsystem. This critical component is responsible for translating that internal un-\\nderstanding and knowledge into concrete interactions and actions within its\\nenvironment.\\n6 Execution System\\nThis system enables the agent to interact with its environment. It encompasses\\nthe mechanisms for tool orchestration, action invocation, and the immediate\\nprocessing of action outcomes [61]. LLM agents interact with their environment\\nand execute actions through several key mechanisms that bridge the gap between\\nlanguage understanding and real-world task automation [21]. These mechanisms\\ninclude:\\n6.1 Tool and API Integration\\nThe most fundamental way LLM agents execute actions is through structured\\ntool calling or function calling capabilities. Agents are given predefined functions,'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 29, 'page_label': '30'}, page_content='include:\\n6.1 Tool and API Integration\\nThe most fundamental way LLM agents execute actions is through structured\\ntool calling or function calling capabilities. Agents are given predefined functions,\\nlike file operations, database queries, web requests, or system commands, that\\ncorrespond to particular actions they can perform. The agent generates structured\\noutputs (typically JSON) that specify which tool to use and what parameters\\nto provide. With this method, agents can carry out specific tasks like sending\\nemails, generating files, performing computations, or getting data from other\\nsystems. [61].\\n6.2 Multimodal Action Spaces\\nMultimodal action spaces represent one of the most significant advances in LLM\\nagent capabilities, enabling them to interact with environments beyond pure text\\ninterfaces [8,70]. Here’s a deeper exploration:\\nVisual Interface Automation:LLM agents can control graphical user inter-\\nfaces through computer vision and automation frameworks to generate precise'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 29, 'page_label': '30'}, page_content='interfaces [8,70]. Here’s a deeper exploration:\\nVisual Interface Automation:LLM agents can control graphical user inter-\\nfaces through computer vision and automation frameworks to generate precise\\nmouse clicks, keyboard inputs, and drag-and-drop operations [41]. This capa-\\nbility allows agents to automate tasks in any software application, from web\\nbrowsers to desktop applications, even when no programmatic API exists. The\\ntechnical implementation typically involves vision-language models that can\\nprocess screenshots and generate coordinate-based actions, or integration with\\nUI automation libraries that can identify elements through accessibility trees or\\nDOM structures [46].'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 30, 'page_label': '31'}, page_content='Building Autonomous LLM Agents 31\\nCode Generation and Execution:A particularly powerful multimodal capa-\\nbility is dynamic code generation where agents write executable code in various\\nprogramming languages to solve specific problems. This approach is especially\\nvaluable for data manipulation tasks, complex calculations, file processing, and\\nintegration between different systems. Agents can write Python scripts for data\\nanalysis, generate SQL queries for database operations, create shell scripts for\\nsystem administration, or produce HTML/CSS/JavaScript for web-based solu-\\ntions [10,42].\\nRobotic and Physical System Control:In robotics applications, LLM\\nagents can control physical systems through appropriate APIs and sensor in-\\ntegrations [61]. They process sensor data (cameras, force sensors, temperature\\nsensors) to understand the physical environment, generate motion plans and\\ncontrol commands, coordinate multiple actuators and subsystems, and adapt to'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 30, 'page_label': '31'}, page_content='sensors) to understand the physical environment, generate motion plans and\\ncontrol commands, coordinate multiple actuators and subsystems, and adapt to\\nreal-time feedback from the physical world.\\n6.3 Integration Challenges and Solutions\\nMultimodal execution presents several technical challenges [21]. Latency and\\ncoordination issues arise when combining different modalities, as visual pro-\\ncessing and physical actions often require different timing considerations. Error\\npropagation becomes more complex when failures can occur at multiple levels\\n(perception, planning, execution). State synchronization requires careful man-\\nagement to ensure the agent’s understanding remains consistent across different\\nmodalities [27].\\n7 Discussion\\n7.1 Limitations\\nWhile our review sheds light on the foundational elements of intelligent LLM\\nagents, several limitations warrant consideration. Firstly, these agents currently\\nfail at certain operations that humans can easily perform, largely due to a'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 30, 'page_label': '31'}, page_content='agents, several limitations warrant consideration. Firstly, these agents currently\\nfail at certain operations that humans can easily perform, largely due to a\\nlack of sufficient experience interacting in specific environments. Teaching these\\nexperiences to LLMs is exceptionally costly, often requiring extensive fine-tuning.\\nThis challenge is compounded by the fact that many advanced models are closed-\\nsource, making it difficult to fine-tune this models. Moreover, acquiring the\\nnecessary data for targeted training is also time-consuming. Secondly, while\\nLLMs excel at generating and understanding text, their ability to generate\\nprecise actions in the real world or within graphical user interfaces (GUIs)\\nremains limited. Thirdly, despite advancements, visual perception in these agents\\nis not yet as robust as required, with many mistakes stemming from an incomplete\\nor inaccurate understanding of the environment.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 31, 'page_label': '32'}, page_content='32 de Lamo et al.\\n7.2 Implications\\nThe review presented in this paper has significant implications for the future\\nof artificial intelligence. By demonstrating that LLM agents can move beyond\\nsimple language generation to exhibit capabilities akin to human cognition, we\\nopen doors for their application in highly complex domains requiring nuanced\\nunderstanding and decision-making, such as scientific discovery, personalized\\neducation, and advanced robotics. The modular design and the integration of\\nspecialized components suggest a promising path towards building more robust\\nand adaptable AI systems that can learn and evolve. Furthermore, the memory\\ncapabilities highlighted in this review could lead to the development of AI\\nassistants that are not only more helpful but also more reliable and context-\\naware.\\n7.3 Possible Extensions\\nFuture research can extend this work in several promising directions. One critical\\narea is to explore more advanced mechanisms for knowledge acquisition and'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 31, 'page_label': '32'}, page_content='aware.\\n7.3 Possible Extensions\\nFuture research can extend this work in several promising directions. One critical\\narea is to explore more advanced mechanisms for knowledge acquisition and\\nself-correction in LLM agents, enabling them to continuously learn from new\\nexperiences and rectify errors without extensive human intervention. However,\\nit would also be very interesting to investigate how these agents can learn to\\naccomplish a task after just a single demonstration with human help, subse-\\nquently performing it autonomously. This “learn-from-one-shot” paradigm could\\nsignificantly reduce the cost and effort of training LLM agents in new domains.\\nAn even more ambitious extension could be developing agents where humans act\\nas assistants. This would improve productivity by 10x.\\n8 Conclusion\\nThis paper set out to explore the intricate design and implementation strategies\\nfor creating intelligent LLM agents, focusing on their core capabilities across'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 31, 'page_label': '32'}, page_content='8 Conclusion\\nThis paper set out to explore the intricate design and implementation strategies\\nfor creating intelligent LLM agents, focusing on their core capabilities across\\nperception, memory, reasoning, planning, and execution. Our exploration revealed\\nthat LLM agents are not merely large language models, but complex systems built\\nupon specialized components that mimic human cognitive processes. Specifically,\\nwe reviewed reasoning techniques, such as Chain-of-Thought and Tree-of-Thought,\\nthat significantly enhance an agent’s problem-solving abilities.\\nMoreover, the review showed that using different experts to focus on each\\npart of the reasoning improves performance. Another conclusion from the review\\nis that robust memory systems are crucial for personalized responses, continuous\\nlearning, and long-term coherence and adaptability.\\nFurthermore, our analysis highlighted the critical role of a well-implemented'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 31, 'page_label': '32'}, page_content='learning, and long-term coherence and adaptability.\\nFurthermore, our analysis highlighted the critical role of a well-implemented\\nperception system in enabling agents to interpret diverse environmental inputs,\\nand the necessity of action systems for translating decisions into tangible outcomes.\\nThese findings directly address our initial objectives by illustrating how specific\\narchitectural designs and advanced techniques contribute to building more capable'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 32, 'page_label': '33'}, page_content='Building Autonomous LLM Agents 33\\nand generalized LLM agents, moving beyond simple workflow automation towards\\ntruly autonomous and intelligent entities.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 33, 'page_label': '34'}, page_content='34 de Lamo et al.\\nReferences\\n1. Alazraki, L., Mozes, M., Campos, J.A., Yi-Chern, T., Rei, M., Bartolo, M.: No\\nneed for explanations: Llms can implicitly learn from mistakes in-context. arXiv\\npreprint (2025), https://arxiv.org/abs/2502.08550\\n2. Anthony Brohan, e.a.: Rt-2: Vision-language-action models transfer web knowledge\\nto robotic control. arXiv preprint (2023), https://arxiv.org/abs/2307.15818\\n3. Anthropic: Building effective agents. https://www.anthropic.com/engineering/\\nbuilding-effective-agents (2024), accessed: June 5 2025\\n4. Besta, M., Blach, N., Kubicek, A., Gerstenberger, R., Podstawski, M., Gianinazzi,\\nL., Gajda, J., Lehmann, T., Niewiadomski, H., Nyczyk, P., Hoefler, T.: Graph of\\nThoughts: Solving Elaborate Problems with Large Language Models. arXiv preprint\\n(2023), https://arxiv.org/abs/2308.09687\\n5. Cai, W., Jiang, J., Wang, F., Tang, J., Kim, S., Huang, J.: A survey on mixture\\nof experts in large language models. arXiv preprint (2025), https://arxiv.org/pdf/'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 33, 'page_label': '34'}, page_content='5. Cai, W., Jiang, J., Wang, F., Tang, J., Kim, S., Huang, J.: A survey on mixture\\nof experts in large language models. arXiv preprint (2025), https://arxiv.org/pdf/\\n2407.06204.pdf\\n6. Chen, X., Lin, M., Schärli, N., Zhou, D.: Teaching large language models to self-\\ndebug. arXiv preprint (2023), https://arxiv.org/abs/2304.05128\\n7. Chen, Y., Cui, W., Chen, Y., Tan, M., Zhang, X., Zhao, D., Wang, H.: Robogpt:\\nan intelligent agent of making embodied long-term decisions for daily instruction\\ntasks. arXiv preprint (2024), https://arxiv.org/abs/2311.15649\\n8. Deng, X., Gu, Y., Zheng, B., Chen, S., Stevens, S., Wang, B., Sun, H., Su, Y.:\\nMind2web: Towards a generalist agent for the web. arXiv preprint (2023), https:\\n//arxiv.org/abs/2306.06070\\n9. Florian Bordes, e.a.: An introduction to vision-language models. arXiv preprint\\narXiv:2405.17247 (2024), https://arxiv.org/pdf/2405.17247.pdf\\n10. Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang, Y., Callan, J., Neubig, G.:'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 33, 'page_label': '34'}, page_content='arXiv:2405.17247 (2024), https://arxiv.org/pdf/2405.17247.pdf\\n10. Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang, Y., Callan, J., Neubig, G.:\\nPal: Program-aided language models. arXiv preprint (2023), https://arxiv.org/abs/\\n2211.10435\\n11. Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., Dai, Y., Sun, J., Wang, M.,\\nWang, H.: Retrieval-augmented generation for large language models: A survey.\\narXiv preprint (2024), https://arxiv.org/abs/2312.10997\\n12. Gidey, H.K., Collins, A., Marmsoler, D.: Modeling and verifying dynamic architec-\\ntures with factum studio. In: Formal Aspects of Component Software,FACS 2019,.\\nSpringer (2019). https://doi.org/10.1007/978-3-030-40914-2_13, https://doi.org/\\n10.1007/978-3-030-40914-2_13\\n13. Gidey, H.K., Hillmann, P., Karcher, A., Knoll, A.: Towards cognitive bots: Archi-\\ntectural research challenges. In: Artificial General Intelligence, AGI 2023,. Springer\\n(2023). https://doi.org/10.1007/978-3-031-33469-6_11, https://doi.org/10.1007/'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 33, 'page_label': '34'}, page_content='tectural research challenges. In: Artificial General Intelligence, AGI 2023,. Springer\\n(2023). https://doi.org/10.1007/978-3-031-33469-6_11, https://doi.org/10.1007/\\n978-3-031-33469-6_11\\n14. Gidey, H.K., Hillmann, P., Karcher, A., Knoll, A.: User-like bots for cognitive\\nautomation: A survey. In: Machine Learning, Optimization, and Data Science,\\nLOD 2023,. Springer (2023). https://doi.org/10.1007/978-3-031-53966-4_29, https:\\n//doi.org/10.1007/978-3-031-53966-4_29\\n15. Gidey, H.K., Huber, N., Lenz, A., Knoll, A.: Affordance representation and recogni-\\ntion for Autonomous Agents. In: Proceedings of the Second International Workshop\\non Hypermedia Multi-Agent Systems (HyperAgents 2025), in conjunction with the\\n28th European Conference on Artificial Intelligence (ECAI 2025), Bologna, Italy,\\nOctober 26, 2025. Bologna, Italy (Oct 2025)'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 34, 'page_label': '35'}, page_content='Building Autonomous LLM Agents 35\\n16. Gidey, H.K., Hueber, N., Lenz, A., Knoll, A.: Visual perception patterns for software\\nagents (2025), preprint\\n17. Gidey, H.K., Kesseler, M., Stangl, P., Hillmann, P., Karcher, A.: Document-based\\nknowledge discovery with microservices architecture. In: Bennour, A., Ensari, T.,\\nKessentini, Y., Eom, S. (eds.) Intelligent Systems and Pattern Recognition: ISPR\\n2022. Communications in Computer and Information Science, vol. 1589, pp. 146–\\n161. Springer, Cham (Mar 2022). https://doi.org/10.1007/978-3-031-08277-1_13,\\nhttps://doi.org/10.1007/978-3-031-08277-1_13\\n18. Gidey, H.K., Marmsoler, D.:FACTumStudio. https://habtom.github.io/factum/\\n(2018)\\n19. Gidey, H.K., Marmsoler, D., Ascher, D.: Modeling adaptive self-healing systems.\\nCoRRabs/2304.12773(Apr 2023). https://doi.org/10.48550/arXiv.2304.12773,\\nhttps://arxiv.org/abs/2304.12773\\n20. Gidey, H.K., Marmsoler, D., Eckhardt, J.: Grounded architectures: Using grounded'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 34, 'page_label': '35'}, page_content='CoRRabs/2304.12773(Apr 2023). https://doi.org/10.48550/arXiv.2304.12773,\\nhttps://arxiv.org/abs/2304.12773\\n20. Gidey, H.K., Marmsoler, D., Eckhardt, J.: Grounded architectures: Using grounded\\ntheory for the design of software architectures. In: 2017 IEEE International\\nConference on Software Architecture Workshops (ICSAW). pp. 141–148. IEEE,\\nGothenburg, Sweden (Apr 2017). https://doi.org/10.1109/ICSAW.2017.41, https:\\n//doi.org/10.1109/ICSAW.2017.41\\n21. Guo, T., Chen, X., Wang, Y., Chang, R., Pei, S., Chawla, N.V., Wiest, O., Zhang,\\nX.: Large language model based multi-agents: A survey of progress and challenges.\\narXiv preprint (2024), https://arxiv.org/abs/2402.01680\\n22. Hamdan, S., Yuret, D.: How much do llms learn from negative examples? arXiv\\npreprint (2025), https://arxiv.org/abs/2503.14391\\n23. Han, S., Zhang, Q., Yao, Y., Jin, W., Xu, Z.: Llm multi-agent systems: Challenges\\nand open problems. arXiv preprint (2025), https://arxiv.org/abs/2402.03578'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 34, 'page_label': '35'}, page_content='23. Han, S., Zhang, Q., Yao, Y., Jin, W., Xu, Z.: Llm multi-agent systems: Challenges\\nand open problems. arXiv preprint (2025), https://arxiv.org/abs/2402.03578\\n24. Hao, S., Gu, Y., Ma, H., Hong, J.J., Wang, Z., Wang, D.Z., Hu, Z.: Reasoning\\nwith language model is planning with world model. arXiv preprint (2023), https:\\n//arxiv.org/abs/2305.14992\\n25. Huang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H., Chen, Q., Peng,\\nW., Feng, X., Qin, B., Liu, T.: A survey on hallucination in large language\\nmodels: Principles, taxonomy, challenges, and open questions. ACM Transac-\\ntions on Information Systems43(2) (2025). https://doi.org/10.1145/3703155,\\nhttp://dx.doi.org/10.1145/3703155\\n26. Huang, X., Liu, W., Chen, X., Wang, X., Wang, H., Lian, D., Wang, Y., Tang,\\nR., Chen, E.: Understanding the planning of llm agents: A survey. arXiv preprint\\n(2024), https://arxiv.org/abs/2402.02716\\n27. Hwang, J., Tani, J.: Seamless integration and coordination of cognitive skills'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 34, 'page_label': '35'}, page_content='(2024), https://arxiv.org/abs/2402.02716\\n27. Hwang, J., Tani, J.: Seamless integration and coordination of cognitive skills\\nin humanoid robots: A deep learning approach. arXiv preprint (2017), https:\\n//arxiv.org/abs/1706.02423\\n28. Jain, J., Yang, J., Shi, H.: Vcoder: Versatile vision encoders for multimodal large\\nlanguage models. arXiv preprint arXiv:2312.14233 (2023), https://arxiv.org/pdf/\\n2312.14233.pdf\\n29. Jin, H., Huang, L., Cai, H., Yan, J., Li, B., Chen, H.: From LLMs to LLM-based\\nagents for software engineering: A survey of current, challenges and future. arXiv\\npreprint (2024), https://arxiv.org/pdf/2408.02479\\n30. Kil, J., Song, C.H., Zheng, B., Deng, X., Su, Y., Chao, W.L.: Dual-view visual\\ncontextualization for web navigation. arXiv preprint (2024), https://arxiv.org/abs/\\n2402.04476\\n31. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler,\\nH., Lewis, M., tau Yih, W., Rocktäschel, T., Riedel, S., Kiela, D.: Retrieval-'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 35, 'page_label': '36'}, page_content='36 de Lamo et al.\\naugmented generation for knowledge-intensive nlp tasks. arXiv preprint (2021),\\nhttps://arxiv.org/abs/2005.11401\\n32. Li, M., Zhao, Y., Yu, B., Song, F., Li, H., Yu, H., Li, Z., Huang, F., Li, Y.: Api-\\nbank: A comprehensive benchmark for tool-augmented llms. arXiv preprint (2023),\\nhttps://arxiv.org/abs/2304.08244\\n33. Li, X., Wang, S., Zeng, S., Wu, Y., Yang, Y.: A survey on LLM-based multi-agent\\nsystems: workflow, infrastructure, and challenges. Vicinagearth1, 9 (2024). https://\\ndoi.org/10.1007/s44336-024-00009-2, https://doi.org/10.1007/s44336-024-00009-2\\n34. Li, Y., Lai, Z., Bao, W., Tan, Z., Dao, A., Sui, K., Shen, J., Liu, D., Liu, H., Kong,\\nY.: Visual large language models for generalized and specialized applications. arXiv\\npreprint arXiv:2501.02765 (2025), https://arxiv.org/abs/2501.02765\\n35. Liu, T., Ren, J., Zhang, C.: Planning with large language models via corrective\\nre-prompting. arXiv preprint (2023), https://arxiv.org/pdf/2305.018323.pdf'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 35, 'page_label': '36'}, page_content='35. Liu, T., Ren, J., Zhang, C.: Planning with large language models via corrective\\nre-prompting. arXiv preprint (2023), https://arxiv.org/pdf/2305.018323.pdf\\n36. Lu, Z., Lu, W., Tao, Y., Dai, Y., Chen, Z., Zhuang, H., Chen, C., Peng, H.,\\nZeng, Z.: Decompose, plan in parallel, and merge: A novel paradigm for large\\nlanguage models based planning with multiple constraints. arXiv preprint (2025),\\nhttps://arxiv.org/abs/2506.02683\\n37. Macedo, J., Gidey, H.K., Rebuli, K.B., Machado, P.: Evolving user interfaces: A\\nneuroevolution approach for natural human-machine interaction. In: Johnson, C.,\\nRebelo, S.M., Santos, I. (eds.) Artificial Intelligence in Music, Sound, Art and\\nDesign: 13th International Conference, EvoMUSART 2024, Held as Part of EvoStar\\n2024, Aberystwyth, UK, April 3–5, 2024, Proceedings. Lecture Notes in Computer\\nScience, vol. 14633, pp. 246–264. Springer, Cham (Apr 2024). https://doi.org/10.\\n1007/978-3-031-56992-0_16, https://doi.org/10.1007/978-3-031-56992-0_16'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 35, 'page_label': '36'}, page_content='Science, vol. 14633, pp. 246–264. Springer, Cham (Apr 2024). https://doi.org/10.\\n1007/978-3-031-56992-0_16, https://doi.org/10.1007/978-3-031-56992-0_16\\n38. Madaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao, L., Wiegreffe, S., Alon,\\nU., Dziri, N., Prabhumoye, S., Yang, Y., Gupta, S., Majumder, B.P., Hermann,\\nK., Welleck, S., Yazdanbakhsh, A., Clark, P.: Self-refine: Iterative refinement with\\nself-feedback. arXiv preprint (2023), https://arxiv.org/abs/2303.17651\\n39. Mi, Y., Gao, Z., Ma, X., Li, Q.: Building llm agents by incorporating insights from\\ncomputer systems. arXiv preprint arXiv:2504.04485 (2025), https://arxiv.org/pdf/\\n2504.04485v1.pdf\\n40. Nakano, R., Hilton, J., Balaji, S., Wu, J., Ouyang, L., Kim, C., Hesse, C., Jain,\\nS., Kosaraju, V., Saunders, W., Jiang, X., Cobbe, K., Eloundou, T., Krueger,\\nG., Button, K., Knight, M., Chess, B., Schulman, J.: Webgpt: Browser-assisted\\nquestion-answering with human feedback. arXiv preprint (2022), https://arxiv.org/\\nabs/2112.09332'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 35, 'page_label': '36'}, page_content='G., Button, K., Knight, M., Chess, B., Schulman, J.: Webgpt: Browser-assisted\\nquestion-answering with human feedback. arXiv preprint (2022), https://arxiv.org/\\nabs/2112.09332\\n41. Niu, R., Li, J., Wang, S., Fu, Y., Hu, X., Leng, X., Kong, H., Chang, Y., Wang,\\nQ.: Screenagent: A vision language model-driven computer control agent. In: Pro-\\nceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intel-\\nligence. pp. 6433–6441. IJCAI-2024, International Joint Conferences on Artifi-\\ncial Intelligence Organization (Aug 2024). https://doi.org/10.24963/ijcai.2024/711,\\nhttp://dx.doi.org/10.24963/ijcai.2024/711\\n42. OpenAI: Code interpreter. OpenAI Platform (2025), https://platform.openai.com/\\ndocs/assistants/tools/code-interpreter, accessed: 26 July 2025\\n43. OSWorld Team: Osworld: Benchmarking multimodal agents for open-ended tasks\\nin real computer environments. https://os-world.github.io/ (2024), accessed: 26\\nJuly 2025'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 35, 'page_label': '36'}, page_content='43. OSWorld Team: Osworld: Benchmarking multimodal agents for open-ended tasks\\nin real computer environments. https://os-world.github.io/ (2024), accessed: 26\\nJuly 2025\\n44. Patil, S.G., Zhang, T., Wang, X., Gonzalez, J.E.: Gorilla: Large language model\\nconnected with massive apis. arXiv preprint (2023), https://arxiv.org/pdf/2305.\\n15334'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 36, 'page_label': '37'}, page_content='Building Autonomous LLM Agents 37\\n45. Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G.,\\nAskell, A., Mishkin, P., Clark, J., Krueger, G., Sutskever, I.: Learning transferable\\nvisual models from natural language supervision. arXiv preprint arXiv:2103.00020\\n(2021), https://arxiv.org/abs/2103.00020\\n46. Rawles, C., Li, A., Rodriguez, D., Riva, O., Lillicrap, T.: Android in the wild:\\nA large-scale dataset for android device control. arXiv preprint (2023), https:\\n//arxiv.org/abs/2307.10088\\n47. Schick, T., Dwivedi-Yu, J., Dessì, R., Raileanu, R., Lomeli, M., Zettlemoyer, L.,\\nCancedda, N., Scialom, T.: Toolformer: Language models can teach themselves to\\nuse tools. arXiv preprint (2023), https://arxiv.org/pdf/2302.04761\\n48. Shen, Y., Song, K., Tan, X., Li, D., Lu, W., Zhuang, Y.: Hugginggpt: Solving ai\\ntasks with chatgpt and its friends in hugging face. arXiv preprint (2023), https:\\n//arxiv.org/abs/2303.17580'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 36, 'page_label': '37'}, page_content='48. Shen, Y., Song, K., Tan, X., Li, D., Lu, W., Zhuang, Y.: Hugginggpt: Solving ai\\ntasks with chatgpt and its friends in hugging face. arXiv preprint (2023), https:\\n//arxiv.org/abs/2303.17580\\n49. Shinn, N., Cassano, F., Berman, E., Gopinath, A., Narasimhan, K., Yao, S.: Re-\\nflexion: Language agents with verbal reinforcement learning. arXiv preprint (2023),\\nhttps://arxiv.org/abs/2303.11366\\n50. Song, S., Li, X., Li, S., Zhao, S., Yu, J., Ma, J., Mao, X., Zhang, W.: How to bridge\\nthe gap between modalities: Survey on multimodal large language model. arXiv\\npreprint arXiv:2311.07594 (2025), https://arxiv.org/abs/2311.07594\\n51. Talebirad, Y., Nadiri, A.: Multi-agent collaboration: Harnessing the power of\\nintelligent llm agents. arXiv preprint (2023), https://arxiv.org/abs/2306.03314\\n52. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser,\\nŁ., Polosukhin, I.: Attention is all you need. arXiv preprint arXiv:1706.03762 (2017),'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 36, 'page_label': '37'}, page_content='52. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser,\\nŁ., Polosukhin, I.: Attention is all you need. arXiv preprint arXiv:1706.03762 (2017),\\nhttps://arxiv.org/pdf/1706.03762.pdf\\n53. Wang, H., Li, T., Deng, Z., Roth, D., Li, Y.: Devil’s advocate: Anticipatory reflection\\nfor llm agents. arXiv preprint (2024), https://arxiv.org/abs/2405.16334\\n54. Wang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z.Y., Tang, J.,\\nChen, X., Lin, Y., Zhao, W.X., Wei, Z., Wen, J.R.: A survey on large language\\nmodel based autonomous agents. arXiv preprint (2025), https://arxiv.org/pdf/2308.\\n11432.pdf\\n55. Wang, L., Xu, W., Lan, Y., Hu, Z., Lan, Y., Lee, R.K.W., Lim, E.P.: Plan-and-\\nsolve prompting: Improving zero-shot chain-of-thought reasoning by large language\\nmodels. arXiv preprint (2023), https://arxiv.org/abs/2305.04091\\n56. Wang, X., Liu, B.: Oscar: Operating system control via state-aware reasoning and re-'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 36, 'page_label': '37'}, page_content='models. arXiv preprint (2023), https://arxiv.org/abs/2305.04091\\n56. Wang, X., Liu, B.: Oscar: Operating system control via state-aware reasoning and re-\\nplanning. arXiv preprint arXiv:2410.18963 (2024), https://arxiv.org/abs/2410.18963\\n57. Wang, X., Salmani, M., Omidi, P., Ren, X., Rezagholizadeh, M., Eshaghi, A.:\\nBeyond the limits: A survey of techniques to extend the context length in large\\nlanguage models. arXiv preprint (2024), https://arxiv.org/abs/2402.02244\\n58. Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A.,\\nZhou, D.: Self-consistency improves chain of thought reasoning in language models.\\narXiv preprint (2023), https://arxiv.org/abs/2203.11171\\n59. Wang, Z.Z., Mao, J., Fried, D., Neubig, G.: Agent workflow memory. arXiv preprint\\n(2024), https://arxiv.org/abs/2409.07429\\n60. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q.,\\nZhou, D.: Chain-of-thought prompting elicits reasoning in large language models.'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 36, 'page_label': '37'}, page_content='60. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q.,\\nZhou, D.: Chain-of-thought prompting elicits reasoning in large language models.\\narXiv preprint (2023), https://arxiv.org/abs/2201.11903\\n61. Xi, Z., Chen, W., Guo, X., He, W., Ding, Y., Hong, B., Zhang, M., Wang, J., Jin,\\nS., Zhou, E., Zheng, R., Fan, X., Wang, X., Xiong, L., Zhou, Y., Wang, W., Jiang,\\nC., Zou, Y., Liu, X., Yin, Z., Dou, S., Weng, R., Zhang, Q., Qin, W., Zheng, Y.,\\nQiu, X., Huang, X., Gui, T.: The rise and potential of large language model based\\nagents: A survey. arXiv preprint (2023), https://arxiv.org/abs/2309.07864'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 37, 'page_label': '38'}, page_content='38 de Lamo et al.\\n62. Xiang, J., Tao, T., Gu, Y., Shu, T., Wang, Z., Yang, Z., Hu, Z.: Language models\\nmeet world models: Embodied experiences enhance language models. arXiv preprint\\n(2023), https://arxiv.org/abs/2305.10626\\n63. Xu, B., Peng, Z., Lei, B., Mukherjee, S., Liu, Y., Xu, D.: Rewoo: Decoupling\\nreasoning from observations for efficient augmented language models. arXiv preprint\\n(2023), https://arxiv.org/abs/2305.18323\\n64. Yang, J., Zhang, H., Li, F., Zou, X., Li, C., Gao, J.: Set-of-mark prompting unleashes\\nextraordinary visual grounding in gpt-4v. arXiv preprint arXiv:2310.11441 (2023),\\nhttps://arxiv.org/abs/2310.11441\\n65. Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T.L., Cao, Y., Narasimhan, K.: Tree\\nof thoughts: Deliberate problem solving with large language models. arXiv preprint\\n(2023), https://arxiv.org/abs/2305.10601\\n66. Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., Cao, Y.: React:'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 37, 'page_label': '38'}, page_content='(2023), https://arxiv.org/abs/2305.10601\\n66. Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., Cao, Y.: React:\\nSynergizing reasoning and acting in language models. arXiv preprint (2023), https:\\n//arxiv.org/abs/2210.03629\\n67. Zhang, D., Yu, Y., Dong, J., Li, C., Su, D., Chu, C., Yu, D.: Mm-llms: Recent\\nadvances in multimodal large language models. arXiv preprint arXiv:2401.13601\\n(2024), https://arxiv.org/abs/2401.13601\\n68. Zhao, Z., Lee, W.S., Hsu, D.: Large language models as commonsense knowledge\\nfor large-scale task planning. In: Thirty-seventh Conference on Neural Information\\nProcessing Systems (2023), https://openreview.net/forum?id=Wjp1AYB8lH\\n69. Zhong, W., Guo, L., Gao, Q., Ye, H., Wang, Y.: Memorybank: Enhancing large\\nlanguage models with long-term memory. arXiv preprint (2023), https://arxiv.org/\\nabs/2305.10250\\n70. Zhou,S.,Xu,F.F.,Zhu,H.,Zhou,X.,Lo,R.,Sridhar,A.,Cheng,X.,Ou,T.,Bisk,Y.,'), Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 37, 'page_label': '38'}, page_content='language models with long-term memory. arXiv preprint (2023), https://arxiv.org/\\nabs/2305.10250\\n70. Zhou,S.,Xu,F.F.,Zhu,H.,Zhou,X.,Lo,R.,Sridhar,A.,Cheng,X.,Ou,T.,Bisk,Y.,\\nFried, D., Alon, U., Neubig, G.: Webarena: A realistic web environment for building\\nautonomous agents. arXiv preprint (2024), https://arxiv.org/abs/2307.13854\\n71. Zhu, X., Chen, Y., Wang, H., et al.: OSWorld: A realistic benchmark for generalist\\nagents in operating systems. arXiv preprint (2024), https://arxiv.org/pdf/2404.\\n07972\\n72. Zhu, X., Li, Q., Cui, L., Liu, Y.: Large language model enhanced text-to-sql\\ngeneration: A survey. arXiv preprint (2024), https://arxiv.org/abs/2410.06011')]\n"
     ]
    }
   ],
   "source": [
    "print(pages_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c024d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import JinaEmbeddings\n",
    "jina = JinaEmbeddings(\n",
    "                api_key=os.getenv('JINA_API_KEY'),\n",
    "                model_name=\"jina-embeddings-v3\",\n",
    "                \n",
    "            )\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents = pages_split,\n",
    "    persist_directory= persist_directory,\n",
    "    collection_name=collection_name,\n",
    "    embedding=jina\n",
    ")\n",
    "\n",
    "def retriever(str) :\n",
    "    ret= vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 5}\n",
    "    )\n",
    "    return ret.invoke(str)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8640bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm= ChatGoogleGenerativeAI(model='gemini-2.0-flash')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44ec1d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.retrievers import EnsembleRetriever\n",
    "from langchain_classic.retrievers import BM25Retriever\n",
    "\n",
    "bm25_retriver = BM25Retriever.from_documents(pages_split)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c7908ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret= vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 5}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9c7b0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_ret=EnsembleRetriever(retrievers=[ret,bm25_retriver],\n",
    "                               weights=[0.5,0.5]\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8f602b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"What does the acronym DPPM stand for in the context of reasoning?\"\n",
    "results = ensemble_ret.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af13876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc : 1\n",
      "content : DPPM (Decompose, Plan in Parallel, and Merge). It addresses the limitations of\n",
      "existing planning methods, such as:\n",
      "1. Handling heavy constraints\n",
      "2. Carrying errors from the planning of previous steps\n",
      "3. Forgetting the main goal\n",
      "4. Cohesion between subtasks\n",
      "DPPM tackles these problems with the following methods: First, it decomposes\n",
      "the complex task into subtasks. Second, it generates subplans for each of these\n",
      "subtasks concurrently using individual LLM agents. This parallel planning allows\n",
      "each agent to focus only on its assigned subtask, promoting independent work\n",
      "and avoiding the cascading errors that can occur when subplans are sequentially\n",
      "dependent. Finally, DPPM merges these independently generated local subplans\n",
      "into a coherent global plan [36]. Although this method can struggle to adapt\n",
      "well to unexpected environmental problems, this limitation can be mitigated by\n",
      "reflecting on the plan after each execution step.\n",
      "metadata : {'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'creationdate': '', 'producer': 'pikepdf 8.15.1', 'page': 13, 'trapped': '/False', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'page_label': '14', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'total_pages': 38}\n",
      "Doc : 2\n",
      "content : and Merge).\n",
      "First, the agent would decompose the main task into smaller subtasks. Then,\n",
      "in separate calls to an LLM, different planning options would be generated for each\n",
      "subtask. While generating these options, the LLM would consider potential issues\n",
      "that might arise during the execution of each subtask. Based on these anticipated\n",
      "problems, it would propose alternative approaches to either solve or avoid them.\n",
      "This process combines ideas from Tree-of-thought and the Anticipatory Reflection\n",
      "of the “DEVIL’S ADVOCATE” paper mentioned before.\n",
      "Following the Merge step in DPPM, the agent would integrate the different\n",
      "subtask plans into a final, coherent plan to accomplish the overall goal. To do this,\n",
      "it would explore various combinations of the subtask options, ensuring that the\n",
      "resulting plan is logically consistent and that all subplans contribute meaningfully\n",
      "toward completing the main task.\n",
      "Afterthefinalplanisconstructed,itwouldbedividedintogroupsofexecutable\n",
      "metadata : {'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'total_pages': 38, 'title': 'Fundamentals of Building Autonomous LLM Agents', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'page': 17, 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'trapped': '/False', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'page_label': '18', 'producer': 'pikepdf 8.15.1', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244'}\n",
      "Doc : 3\n",
      "content : 26 de Lamo et al.\n",
      "5.2 Short-term memory\n",
      "Short-term memory in LLM agents is analogous to the input information main-\n",
      "tained within the context window, which acts as a temporary workspace [54].\n",
      "Regardless of whether it’s for long-term retention or immediate contextual\n",
      "awareness, the memory module’s effectiveness hinges on what kind of data to\n",
      "store.\n",
      "5.3 What Kind of Data to Store\n",
      "The memory module within an LLM agent’s architecture is designed to store\n",
      "diverse types of information perceived from its environment and interactions.\n",
      "This stored data is then used to make better decisions, enabling the agent to\n",
      "accumulate experiences, evolve, and behave in a more consistent and effective\n",
      "manner.\n",
      "– Experiences:It is beneficial to store records of both successful and failed\n",
      "tasks. Research has indicated that even failed experiences, when appropriately\n",
      "logged and distinguished as such, can be valuable. By explicitly noting a “failed\n",
      "metadata : {'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 25, 'page_label': '26'}\n",
      "Doc : 4\n",
      "content : 20 de Lamo et al.\n",
      "Having illustrated how a single LLM agent can leverage a reasoning system\n",
      "like DPPM, combined with reflection, we now explore how multi-agent sys-\n",
      "tems distribute these processes across specialized components to achieve greater\n",
      "scalability and efficiency.\n",
      "4.5 Multi-Agent Systems\n",
      "Expanding on the idea of multi-agent systems, a single agent can be made up\n",
      "of different specialized “experts,” each of whom focuses on a distinct aspect of\n",
      "the interaction or reasoning. This modularity enables specialization at each step,\n",
      "increasing its capabilities and robustness [5]. Here are some examples of such\n",
      "useful experts that an LLM agent could integrate:\n",
      "– Planning Expert:This expert focuses on strategic thinking and task\n",
      "decomposition. Its role is to break down complex objectives into a series of\n",
      "manageable subtasks. This aligns with the actor component discussed in the\n",
      "reflection system, where agents perform reasoning and planning to undertake\n",
      "complex tasks [33].\n",
      "metadata : {'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'page_label': '20', 'trapped': '/False', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'page': 19, 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'creationdate': '', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'producer': 'pikepdf 8.15.1', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'total_pages': 38}\n",
      "Doc : 5\n",
      "content : specific feedback.\n",
      "The paper “DEVIL’S ADVOCATE: Anticipatory Reflection for LLM\n",
      "Agents” [53] introduces a distinct perspective: Anticipatory Reflection. This\n",
      "consists of the agent proactively reflecting on potential failures and considering\n",
      "alternative remedies before executing an action, essentially acting as a “devil’s\n",
      "advocate” to challenge its own proposed steps. This front-loaded introspection\n",
      "enhances consistency and adaptability by allowing the agent to anticipate and\n",
      "mitigate challenges, improving its ability to navigate complex tasks effectively.\n",
      "4.4 Example of a Reasoning System\n",
      "A reasoning system can be developed by integrating some of the features men-\n",
      "tioned above. Its core mechanism could be DPPM (Decompose, Plan in Parallel,\n",
      "and Merge).\n",
      "First, the agent would decompose the main task into smaller subtasks. Then,\n",
      "in separate calls to an LLM, different planning options would be generated for each\n",
      "metadata : {'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'total_pages': 38, 'creationdate': '', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'page': 17, 'producer': 'pikepdf 8.15.1', 'page_label': '18', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'trapped': '/False', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1'}\n",
      "Doc : 6\n",
      "content : and second, the “subplan” step, where for each subtask a plan is formulated [26].\n",
      "This systematic breakdown helps in navigating intricate real-world scenarios that\n",
      "would otherwise be challenging to address with a single-step planning process.\n",
      "Current methodologies for task decomposition broadly fall into two categories:\n",
      "Decomposition first and Interleaved decomposition [26]. Decomposition first\n",
      "methods, as seen in systems like HuggingGPT [48] and Plan-and-Solve [55],\n",
      "initially decompose the entire task into sub-goals and then proceed to plan\n",
      "for each sub-goal sequentially. HuggingGPT, for instance, explicitly instructs\n",
      "the LLM to break down multimodal tasks and define dependencies between\n",
      "subtasks [48]. A slightly modified version of the Decomposition first approach is\n",
      "DPPM (Decompose, Plan in Parallel, and Merge). It addresses the limitations of\n",
      "existing planning methods, such as:\n",
      "1. Handling heavy constraints\n",
      "2. Carrying errors from the planning of previous steps\n",
      "metadata : {'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 13, 'page_label': '14'}\n",
      "Doc : 7\n",
      "content : 16 de Lamo et al.\n",
      "– Self-consistent CoT (CoT-SC):This approach generates various reasoning\n",
      "paths and their corresponding answers using Chain of Thought (CoT), then\n",
      "selects the answer with the highest frequency as the final output [58].\n",
      "– Tree-of-Thought (ToT) and Graph of Thoughts (GoT):ToT gener-\n",
      "ates plans using a tree-like reasoning structure where each node represents\n",
      "an intermediate “thought.” The selection of these steps is based on LLM\n",
      "evaluations. Unlike CoT-SC, ToT queries LLMs for each reasoning step [65].\n",
      "Graph-of-Thought (GoT) extends the tree-like reasoning structure of ToT\n",
      "to graph structures. It supports arbitrary thought aggregation and allows\n",
      "for transformations of thoughts, leading to more powerful prompting strate-\n",
      "gies [4].\n",
      "Fig.6.Schematic illustrating various approaches to problem solving with LLMs [65].\n",
      "– LLM-MCTS and RAP:These methods leverage LLMs as a heuristic policy\n",
      "function for the Monte Carlo Tree Search (MCTS). Multiple potential actions\n",
      "metadata : {'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'total_pages': 38, 'creationdate': '', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'page': 15, 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'page_label': '16', 'trapped': '/False', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'producer': 'pikepdf 8.15.1'}\n",
      "Doc : 8\n",
      "content : and process. The complexity of the environment and the kinds of information\n",
      "required determine the architecture. This challenge can be approached in four\n",
      "ways: text-based, multimodal, information tree/structured data, and tool-based.\n",
      "3.1 Text-Based Perception (Pure LLM)\n",
      "The simplest form in which the environment is described is purely in text. The\n",
      "LLM receives and processes this text description. In this mode, the environment\n",
      "provides textual observations directly to the LLM’s prompt. This could be a\n",
      "description of the current state, recent events, or results of actions taken. In this\n",
      "environment, the perception system does not need to intervene.\n",
      "metadata : {'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:e76afa9)', 'creationdate': '', 'author': 'Victor de Lamo Castrillo; Habtom Kahsay Gidey; Alexander Lenz; Alois Knoll', 'doi': 'https://doi.org/10.48550/arXiv.2510.09244', 'license': 'http://creativecommons.org/licenses/by-nc-nd/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Fundamentals of Building Autonomous LLM Agents', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2510.09244v1', 'source': 'pdf/Fundamentals of Building Autonomous LLM.pdf', 'total_pages': 38, 'page': 5, 'page_label': '6'}\n"
     ]
    }
   ],
   "source": [
    "for i,doc in enumerate(results):\n",
    "    print(\"Doc :\",i+1)\n",
    "    print('content :' ,doc.page_content)\n",
    "    print(\"metadata :\",doc.metadata)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82fff28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, based on the provided context, here's a summary of DPPM (Decompose, Plan in Parallel, and Merge) and its role in LLM agents, along with related concepts:\n",
      "\n",
      "**DPPM: Decompose, Plan in Parallel, and Merge**\n",
      "\n",
      "*   **What it is:** DPPM is a reasoning system designed to improve the planning capabilities of LLM agents. It addresses limitations found in other planning methods.\n",
      "\n",
      "*   **The Problem it Solves:**\n",
      "    *   Handling complex constraints.\n",
      "    *   Cascading errors from previous planning steps.\n",
      "    *   Forgetting the main goal.\n",
      "    *   Lack of cohesion between subtasks.\n",
      "\n",
      "*   **How it Works:**\n",
      "    1.  **Decompose:** The complex task is broken down into smaller, manageable subtasks.\n",
      "    2.  **Plan in Parallel:** Individual LLM agents generate subplans for each subtask concurrently.  This allows each agent to focus on its specific subtask, preventing cascading errors that can occur with sequential planning.  During this stage, potential issues are considered, and alternative approaches are generated. This is inspired by \"DEVIL'S ADVOCATE\" approach of anticipatory reflection.\n",
      "    3.  **Merge:** The independently generated subplans are integrated into a coherent global plan.  Various combinations of subtask options are explored to ensure logical consistency and that each subplan contributes to the overall goal.\n",
      "\n",
      "*   **Adaptability:** DPPM may struggle with unexpected environmental problems. This can be mitigated by reflecting on the plan after each execution step.\n",
      "\n",
      "**DPPM as Part of a Reasoning System**\n",
      "\n",
      "*   DPPM can be a core mechanism in a broader reasoning system for LLM agents.\n",
      "*   After the final plan is constructed, it is divided into groups of executable actions.\n",
      "\n",
      "**Multi-Agent Systems and Specialization**\n",
      "\n",
      "*   The concept of DPPM can be extended to multi-agent systems, where different \"expert\" agents specialize in specific aspects of the interaction or reasoning process.\n",
      "*   **Planning Expert:** An example of a specialized agent is a \"Planning Expert,\" which focuses on strategic thinking and task decomposition, breaking down complex objectives into manageable subtasks.\n",
      "\n",
      "**Other Relevant Planning/Reasoning Concepts Mentioned:**\n",
      "\n",
      "*   **Decomposition First vs. Interleaved Decomposition:** Two broad categories of task decomposition methods. Decomposition first methods (like HuggingGPT and Plan-and-Solve) decompose the entire task upfront, then plan for each sub-goal sequentially.\n",
      "*   **Tree-of-Thought (ToT) and Graph of Thoughts (GoT):** Reasoning approaches that use tree-like (ToT) or graph-like (GoT) structures to represent intermediate \"thoughts\" or reasoning steps.\n",
      "*   **LLM-MCTS and RAP:** Methods that use LLMs as a heuristic policy function for Monte Carlo Tree Search (MCTS).\n",
      "*   **Self-consistent CoT (CoT-SC):** Generates various reasoning paths and selects the most frequent answer.\n",
      "*   **Anticipatory Reflection (\"Devil's Advocate\"):** Proactively reflecting on potential failures and considering alternative remedies before execution.\n",
      "\n",
      "**Memory in LLM Agents**\n",
      "\n",
      "*   **Short-term Memory:** Analogous to the context window.\n",
      "*   **What to Store:** The memory module stores diverse information, including experiences (both successful and failed tasks).  Failed experiences, when logged appropriately, can be valuable.\n"
     ]
    }
   ],
   "source": [
    "answer=llm.invoke(f'this is the relevent context {results} based on this and your understanding give me appropriate answer best to your knowledge ')\n",
    "print(answer.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myLegal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
